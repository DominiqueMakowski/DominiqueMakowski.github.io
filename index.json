[{"authors":null,"categories":null,"content":"Trained as clinical neuropsychologist, CBT psychotherapist (and others), I am currently working as a postdoc at the Clinical Brain Lab in Singapore, in which I lead the Reality Bending Team üßô. I\u0026rsquo;m fluent in French, English, Polish, Python, and currently learning Italian. My main figures of reference are Marcus Aurelius, Sisyphus and Yoda. My interests include scientific methodology, history of art and religion, and philosophy. My research focuses on aspects of reality bending (e.g., fiction, deception, fake news, illusions, and altered states of consciousness such as through meditation or immersion). I also try to improve the access to advanced analysis techniques by developing open-source software and tools.\n  Download my resum√©.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0ecb725ef6a3c46e9b81260cca2f6e62","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Trained as clinical neuropsychologist, CBT psychotherapist (and others), I am currently working as a postdoc at the Clinical Brain Lab in Singapore, in which I lead the Reality Bending Team üßô.","tags":null,"title":"Dominique Makowski","type":"authors"},{"authors":["Dominique Makowski"],"categories":["Reproducibility"],"content":"How to sync two folders in two separate GitHub repositories The Problem I have a personal website, stored in a GitHub repo (and hosted via GitHub pages), as well as a lab website (a \u0026ldquo;company\u0026rdquo; website, if you will). Both are fairly similar, as they are built using Wowchemy\u0026rsquo;s academic theme. Importantly, there is a blog in the company websites with posts, but I have one on my personal website too. I would like that every time I post something on my website, that it gets automatically copied over to the company website. So that I don\u0026rsquo;t have to manually maintain the content at two separate places.\nThe Solution  The first step is to go to the settings of your GitHub account, to developers settings, and to personal access tokens. You have to generate a token, and tick the repo authorizations. Copy-paste the key. Go to the settings of the personal website repo (the source from which the content will be copied), to \u0026ldquo;Secrets\u0026rdquo;, and add a new secret called \u0026ldquo;API_TOKEN_GITHUB\u0026rdquo; (with the key you just copied). Create a new GitHub action workflow such as this one. The things to change are the source_file, destination_repo and destination_folder.  Tada üéâ Everytime I push to my personal repo, the new content of one of the subfolder gets copied to another repo.\nNote: this is a one-way sync, so updates on the target repo won\u0026rsquo;t affect the source repo (but might get overridden!).\n Thanks for reading! Do not hesitate to share or tweet this post, or leave a comment below ü§ó\n","date":1635638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635638400,"objectID":"9e5bdcca259c3d77bd42122add334017","permalink":"https://dominiquemakowski.github.io/post/2021-10-31-sync_two_repos/","publishdate":"2021-10-31T00:00:00Z","relpermalink":"/post/2021-10-31-sync_two_repos/","section":"post","summary":"Say you have a repo A, in which you want to duplicate some content with repo B. You can do that easily using GitHub actions.","tags":["R","Reproducibility"],"title":"How to sync two folders in two separate GitHub repositories","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Reproducibility"],"content":"How to share data analysis scripts with publications? Including data analysis as Supplementary Materials can be a tedious task. How can we simplify the sharing of our work? So that it can be fully appreciated, as well as evaluated, improved, worked on, in a transparent and open way?\nOption 1: Dump the code in a word file Most publication portals don\u0026rsquo;t directly accept code scripts to be included \u0026ldquo;as is\u0026rdquo;. In other words, you cannot upload your manuscript and your .R script just like that. So one option is to copy its content, paste it in a word / pdf document, and Voil√†!\nBut what if you don\u0026rsquo;t have code because you use a point-and-click software? Well, you can note down all the x,y coordinates of your clicks so that one can reproduce the steps and all the clicks. Just kidding, if you don\u0026rsquo;t have a script, then may god have mercy on your soul.\nWhy is that a terrible solution? Because let\u0026rsquo;s face it, unstructured code dumps are horrific. Nobody wants to read it, it does not make justice to your work, and it\u0026rsquo;s still tedious to create! You have to re-do it everytime you modify your code. And it\u0026rsquo;s even worse if you want to include all the outputs, figures, tables that are generated by the code? Data analysis is not just the code, but everything that comes with it and that allowed you to make the conclusions that you made.\nOption 2: Use Rmarkdown Rmarkdown is a \u0026ldquo;framework\u0026rdquo; that allows you to have files (.Rmd) that can contain a mix of text and code (and not only R, but also Python for instance!).\nIt can be used to write comprehensive \u0026ldquo;reports\u0026rdquo; that include all your thoughts, motivations and interpretations of the results. And the great thing about it is that these files can be converted into beautiful and readable documents like PDF, Word or HTML. It will automatically embed the code and its generated output (as text, tables or figures) alongside the text.\nIt is an awesome way to write statistical reports, and can even be used to create many other non-stats related stuff, like APA-formatted manuscripts (great for preprints), books, presentation slides, websites or blogs. It\u0026rsquo;s a must-have skill for every researcher.\nAnd it gets better!\nOption 3: Use our Results Template In the Reality Bending team, we like to have our different projects and studies organized in a consistent way. We heavily use GitHub to store our projects and collaborate on them, and we also like the possibility of making these projects open and accessible (i.e., easy to discover and explore) when the time comes.\nThat\u0026rsquo;s why we came up with a Template folder for storing the materials related to a given study, including well-organized analysis scripts. And what\u0026rsquo;s great about it is that it is setup in a way that allows you to generate multiple files format (word, pdf, html) with a single click (and even without any click, in a fully automatic way)! And what\u0026rsquo;s even greater is that if you decide to upload it to GitHub, you\u0026rsquo;ll have a whole website presenting your data analysis!\nWe use it to have reproducible analysis that we can easily share with publications. We can upload the .pdf or .docx file generated by the template as Supplementary Materials, but we also link the URL of the online repository of the study in the manuscript, where users can access and experience the content in the format that they prefer. It really improves the appeal of a study when the results are trustworthy.\nAll this is easily made possible with our template. Check it out here:\nüëâ https://github.com/RealityBending/TemplateResults üëà\n‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è‚òùÔ∏è\nAnd let us know what you think! You can open an issue on the repo or even contribute to help us improve it :)\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1612915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612915200,"objectID":"232670a7af4fcd34e6b808e2e43cc135","permalink":"https://dominiquemakowski.github.io/post/2021-02-10-template_results/","publishdate":"2021-02-10T00:00:00Z","relpermalink":"/post/2021-02-10-template_results/","section":"post","summary":"Including data analysis as Supplementary Materials can be a tedious task. How can we simplify the sharing of our work? So that it can be fully appreciated, as well as evaluated, improved, worked on, in a transparent and open way?","tags":["R","Reproducibility","Supplementary Materials","Data analysis","Rmarkdown"],"title":"How to share data analysis scripts with publications?","type":"post"},{"authors":["Dominique Makowski"],"categories":["Art","Neuropsychology"],"content":"Name One Thing In This Photo Can you name one thing in the image above? It all looks familiar, but something is off. The image makes \u0026ldquo;sense\u0026rdquo; overall; there are well-defined shapes and objects, that seem to be placed in a plausible - albeit chaotic - fashion, like some random rubbish thrown in the corner of a room. Even the colors, the lightning, the quality, is coherent, and helps making it believable. And yet, chances are you cannot name one single element that composes it.\nThis image, after appearing on twitter in April 2019, surfaced on reddit with the caption \u0026ldquo;This picture is designed to give the viewer the simulated experience of having a stroke (particularly in the occipital lobe of the cerebral cortex, where visual perception occurs.) Everything looks hauntingly familiar but you just can\u0026rsquo;t quite recognize anything\u0026rdquo;, and became subsequently viral. However, the author of the caption later admitted that he made this description up.\nSo where does the image come from?\nOne can trace back the original publication to an instagram account, which author declared having made the image using ArtBreeder.com. This website gives access to an AI algorithm (Generative Adversarial Networks - GAN), commonly used in the processing and generation of images (one mindblowing example can be found on thispersondoesnotexist.com, which generates realistic pictures of non-existing people). There were even some attempts to reverse engineer the process to retrieve what the original image could have been like.\n   After all, it seems like there is no intelligent design behind this image. No clever neuropsychologist carefully crafting a meaningful experience. Just one of these lucky accident.\nNonetheless, it\u0026rsquo;s still an intriguing image, falling in this uncanny abyss of things that we recognize as familiar, but slightly too alien for our sense-seeking brains to dissolve in meaning. Could it tell something about brain processes? Surely, but brain disorders? Maybe.\nThe \u0026ldquo;occipital stroke\u0026rdquo; hypothesis mentioned above suggests, by its formulation, a lesion to the primary visual cortices. However, as neuroscientists know, these brain regions, located at the extreme back of the brain, are mostly supporting lower level aspects of visual processing, and their damage is usually related to alterations of a somewhat different nature than of that above, such as vision loss, visual hallucinations, visual deformations, loss of color, movement, stereoscopy, etc.\nHowever, there is another neuropsychological disorder, referred to as \u0026ldquo;visual agnosia\u0026rdquo;, in which patients experience difficulties to recognize visually presented objects, despite preserving an intact vision. In fact, it is more an umbrella term for different subcategories of deficits, and the image above could be reminiscent of visual agnosia of the associative type, which corresponds to a a specific impairment in the assignment of meaning to a stimulus that is accurately perceived (and can be visually described). This symptom is often related to injuries in the left occipito-temporal region, located on the ventral \u0026ldquo;what\u0026rdquo; stream of the brain (as opposed to the so-called \u0026ldquo;where\u0026rdquo; dorsal stream).\n   Ivan Seal\u0026rsquo;s Art From there, the youtuber Solar Sands helped me discover the artist Ivan Seal, which work is somewhat akin to the image above. They are not purely abstract renditions, or depictions of impossible entities, but plausible objects that sit in this awkward space, deep between boring reality and total weirdness.\n       Thanks for reading! Do not hesitate to tweet and share this post and don\u0026rsquo;t forget to join me on Twitter üê¶ @Dom_Makowski\n","date":1609632000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609632000,"objectID":"d053a3a6366f9a61a24ec0747413b521","permalink":"https://dominiquemakowski.github.io/post/2021-01-03-visual_agnosia/","publishdate":"2021-01-03T00:00:00Z","relpermalink":"/post/2021-01-03-visual_agnosia/","section":"post","summary":"Can you name one thing in this photo? It all looks familiar, but something is off.","tags":["Art","Neuroscience","Neuropsychology"],"title":"What visual agnosia might feel like","type":"post"},{"authors":["Dominique Makowski"],"categories":["Art","Neuropsychology"],"content":"I find fractals fascinating. Their infinitely self-replicating nature illustrates how complex patterns can emerge from very simple rules. But the history of religions and comparative mythology are other hobbies of mine, and today I have a little story about fractals, God, or Hell.\nScience and Religions People often tend to see religion and science as opposites, one obscurantist and the other enlightening, but such generalization overlooks the vast differences between religions, and thus in the world\u0026rsquo;s understanding of their followers.\nLet\u0026rsquo;s take as example some (mostly extinct) religions, like the polytheisms from antiquity. While the interest in humans of the major Gods was often limited (unless it\u0026rsquo;s about beautiful girls, Zeus we see you!), it was usually considered that regular Men have little say in their destiny, and little power to change it. They were toys in Gods' hands, tools at the mercy of their power struggles and agendas not always in line with any form of anthropic benevolence.\n The Fates presiding on Human's destinies, from Disney's Hercules (1997).  In other faiths and philosophies (e.g., Eastern traditions), the world is understood at vastly different scale, and the notion of Self (and/or \u0026ldquo;soul\u0026rdquo;) is extended to encompass many lives. The ultimate goal of breaking the cycle of reincarnation and suffering and ascend to higher states of being is layed out over many lives and, for most people, there isn\u0026rsquo;t much they can do in only one life to escape it. If anything, they must follow a just path, minimize karmic loss, and seek the \u0026ldquo;truth\u0026rdquo; within themselves. A process of Self-mastery and introspection facilitated by various practices, such as meditation.\nOther religions, refered to as \u0026ldquo;orthopraxic\u0026rdquo;, are more than mere beliefs systems (e.g., Islam, as well as some currents of Judeism) and expect followers to follow a set of behaviours and conducts, codifying many aspects of life. The \u0026ldquo;truth\u0026rdquo; has already been revealed to mankind, and we have the choice of following it - and be saved - or not - and be damned. Importantly for our topic, the \u0026ldquo;truth\u0026rdquo; is often contained directly in the scriptures, and can only be attained by studying and learning the sacred texts (with varying degrees of possible interpretation).\nChristianity is different in regards to several aspects. The history of Chritiniarty led it to regards to several aspects.\nCorruption Decadent leaders Crusades Inquisition\nOne can get closer to God by studying his creation, the world.\nOther religions, personal responsability is even further simplified:\nWhat does it have to do with fractals? You\u0026rsquo;ll see, but first, let us make a brief reminder on the king of fractals, the Mandelbrot set.\nhttps://users.math.yale.edu/public_html/People/frame/Fractals/MandelSet/MandelMonk/MandelMonk.html\nwhat is mandelbrot The Mandelbrot set exerts some strange attraction, and these blobs of colour One of the vidualization variant of this set has been immediately attributed a sacred meaning, and has now become known as the Buddhabrot for its eerie ressemblance with the traditional representation of the Buddha in the lotus position.\nImage of Buddhabrot side by side with Buddha.\n Thanks for reading! Do not hesitate to tweet and share this post and don\u0026rsquo;t forget to join me on Twitter üê¶ @Dom_Makowski\n","date":1609632000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609632000,"objectID":"309e6fb673c872e422154a57fafc6885","permalink":"https://dominiquemakowski.github.io/post_drafts/mandelbrot_monk/","publishdate":"2021-01-03T00:00:00Z","relpermalink":"/post_drafts/mandelbrot_monk/","section":"post_drafts","summary":"Can you name one thing in this photo? It all looks familiar, but something is off.","tags":["Art","Neuroscience","Neuropsychology"],"title":"What visual agnosia might feel like","type":"post_drafts"},{"authors":["Dominique Makowski"],"categories":["History"],"content":"Note: It is a work-in-progress. I will add movies as they are out (and when I watch them). Please make suggestions for me to watch and add movies in the comments below.\nNote also that the dates for the periods (themselves partly subjective and conceptual constructs) are to give some markers based on major events, but do not correspond to any abrupt change.\n One often appreciates content when it makes a deeper sense, when it rings the bells of other knowledge and experiences stored in semantic or episodic memory. This is especially the case with historical material (whether realistic or fictionalized). History being very complex and convoluted, it is often hard to get the \u0026ldquo;bigger picture\u0026rdquo; of the full historical context. Thus, I decided, mostly to help my own understanding, to list here historical movies (mostly about western history) in the chronological order of the content they depict, so that the timeline and connections are clearer.\nMiddle-Ages (476 - 1453) Starts with the Fall of Rome until the Fall of Constantinople.\nEarly Middle Ages (476 - 1000) Starts with the Fall of Rome until the 1000 (convenience date).\nHigh Middle Ages (1000 - 1357) Starts from 1000 until the Black Plague.\nKingdom of Heaven (2005)    When: during the Crusades of the 12th century and the reign of the leper King Baldwin IV of Jerusalem (1161 ‚Äì 1185). Where: France and Jerusalem. What: Battle of Hattin (1187). Who: King Baldwin IV of Jerusalem (1161 ‚Äì 1185), Saladin (1137 ‚Äì 1193), Sibylla, Queen of Jerusalem (1160 ‚Äì 1190).  Braveheart (1995)    When: during the reign Edward I \u0026ldquo;Longshanks\u0026rdquo; of England (1239 ‚Äì 1307). Where: Scotland. What: First War of Scottish Independence (1296 - 1328). Who: William Wallace (1270 - 1305), Robert the Bruce (1274 ‚Äì 1329).  Outlaw King (2018)    When: 1304-1307, soon after the death of William Wallace (1270 - 1305), during the reign Edward I \u0026ldquo;Longshanks\u0026rdquo; of England (1239 ‚Äì 1307). Where: Scotland. What: First War of Scottish Independence (1296 - 1328). Who: Robert the Bruce (1274 ‚Äì 1329), Edward I \u0026ldquo;Longshanks\u0026rdquo; of England (1239 ‚Äì 1307), Edward II of England (1284 ‚Äì 1327)  Late Middle Ages (1347 - 1453) Starts with the Black Plague until the Fall of Constantinople and the Hundred Years' War.\nA Knight\u0026rsquo;s Tale (2001)    When: Few years after the Black Plague (which finished around 1351), during the reign of King Edward III of England (1327 ‚Äì 1377). Where: England and France. What: Is mentioned the Battle of Poitiers (1356), a major English victory in the Hundred Years' War. Who: Edward \u0026ldquo;the Black Prince\u0026rdquo; (1330 ‚Äì 1376), son and heir of King Edward III of England (1327 ‚Äì 1377), and the heir to the English throne, who died before his father and so his son, Richard II (1367 - 1400), succeeded to the throne instead until his deposition and take-over by Henry IV in 1399.  The King (2019)    When: End of the reign of Henry IV of England (1367 - 1413), reign of Henry V of England (1386 ‚Äì 1422) and Charles VI \u0026ldquo;le fol\u0026rdquo; of France (1368 ‚Äì 1422). Where: England and France. What: Battle of Agincourt (1415). Who: Henry IV of England (1367 - 1413), Henry V of England (1386 ‚Äì 1422), Charles VI \u0026ldquo;le fol\u0026rdquo; of France (1368 ‚Äì 1422)  The Messenger: The Story of Joan of Arc (1999)    When: Coronation of the Dauphin Charles VII of France (1403 ‚Äì 1461) and Henry VI of England (1421 ‚Äì 1471), the disputed King of France from 1422 to 1453. Where: France. What: Life and death of Joan of Arc (1412 ‚Äì 1431), the Siege of Orl√©ans (1429). Who: Joan of Arc (1412 ‚Äì 1431), Charles VII of France (1403 ‚Äì 1461)  Renaissance (1453 - 1715) Starts with the Fall of Constantinople and the Hundred Years' War until the death of Louis XIV of France.\nThe Other Boleyn Girl (2008)    When: during the reign of Henry VIII of England (1491 ‚Äì 1547). Where: England. What: Life and death of Anne Boleyn (1501 ‚Äì 1536), second wife of Henry VIII after Catherine of Aragon (1485 ‚Äì 1536) and mother of Elizabeth I of England (1533 ‚Äì 1603). Who: Henry VIII of England (1491 ‚Äì 1547), Anne Boleyn (1501 ‚Äì 1536), Mary Boleyn (1500 ‚Äì 1543)  Mary Queen of Scots (2018)    When: during the reign of Elizabeth I of England (1533 ‚Äì 1603), daughter of Anne Boleyn. Where: England. What: Life of Mary, Queen of Scots (1542 ‚Äì 1587), daughter of James V of Scotland and Margaret Tudor (daughter of Henry VII and sister of Henry VIII). Who: Elizabeth I of England (1533 ‚Äì 1603), Mary, Queen of Scots (1542 ‚Äì 1587)  Elizabeth (1998)    When: during the reign of Elizabeth I of England (1533 ‚Äì 1603), daughter of Anne Boleyn. Where: England. What: Death of Mary, Queen of Scots (1587), defeat of the Spanish Armada (1588) Who: Elizabeth I of England (1533 ‚Äì 1603), Mary, Queen of Scots (1542 ‚Äì 1587), Philip II of Spain (1527 ‚Äì1598)  Enlightment (1715 - 1789) Starts with the death of Louis XIV of France until the beginning of the French revolution.\n Thanks for reading! Please leave any suggestions below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1607212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607212800,"objectID":"6f9014efb563d31549f7d1a104608eec","permalink":"https://dominiquemakowski.github.io/post_drafts/historical_movies/","publishdate":"2020-12-06T00:00:00Z","relpermalink":"/post_drafts/historical_movies/","section":"post_drafts","summary":"A guide to better understand western history and historical movies","tags":["Historical Movies","Films","Medieval Films","History"],"title":"Historical Films in their Chronological Context","type":"post_drafts"},{"authors":["Dominique Makowski"],"categories":["Philosophy","Science Fiction"],"content":"Note: this is a thought-experiment, not to be taken too seriously.\nWe live in a simulated universe In his famous simulation argument, the transhumanist Bostrom (2003, 2011) posits that we are living in a computer-generated reality. The logic behind this assumption is that an advanced civilization, with enormous computing power, might want to create agents with a powerful artificial intelligence, that would be evolving in a simulated world (think of an infinitely more advanced The Sims Game). These sims (i.e., the virtual intelligences populating the simulation) might be endowed with consciousness, and live their lives in this world, unable to distinguish its simulated nature from the \u0026ldquo;primary\u0026rdquo; reality. Moreover, similarly to games that are running on many computers in the world, there could be an important number of these simulated worlds. Moreover, it could reach a point where a simulation could be created inside another simulation. Thus, the number of \u0026ldquo;sims\u0026rdquo; would quickly exceed the number of consciousness\u0026rsquo;s living in the primary (i.e., non-computer-generated) reality. Consequently, it is statistically plausible that we are, indeed, simulated \u0026ldquo;sims\u0026rdquo; living in a simulated reality.\n Aliens watching episode 2020 of \"the Earth\" unfold, horrified.  It is to note that Bostrom\u0026rsquo;s argument has been criticized, mocked, revised and updated several times. But beyond the flaws in its argumentation and premisses, it is still a fairly appealing thought experiment, and a fascinating possibility. People have been mis-representing this argument, picturing some alien species playing The Sims with us on mega computers. But albeit Bostrom indeed mostly presents it as a simulation run by other intelligent agents, this idea could be generalized. The simulating system could take many forms, not necessarily created by an intelligent design. It just means that there\u0026rsquo;s a \u0026ldquo;thing\u0026rdquo; (a very scientific term, I know) outside the universe that gives rise to it, one way of another.\nWhat does it change for our lives? Pretty much nothing. Indeed, this thrilling hypothesis is somehow irrelevant from a phenomenological and psychological perspective, for the majority of people cannot help but experience a fully deployed sense of reality. They are (normally) endowed with an intuitive feeling and belief that they are real, existing and belonging to a real world. They rarely doubt it, and even if they do so, it is mostly in a philosophical fashion, that does not entail a genuine sensation of uncertainty toward the nature of the world. This sense of reality is fascinating topic on its own (though I\u0026rsquo;m biased since its my main research topic), independent from the issue of the nature of the universe. Though we could argue that the latter opens up the possibility of tears in the objective reality (either bugs of the system or ways of accessing and modifying the fabric of reality), but this Matrix-like aspect of the simulated reality hypothesis is a topic for another time.\nSo no, the universe being a simulation, aside from being a breath-taking metaphysical consideration, changes practically nothing for our daily lives.\nDetermism Let\u0026rsquo;s put aside this idea of a simulated universe for now and think about determinism. I consider myself, for now, as an ultra-determinist (I should rather say, \u0026ldquo;the world has made me into a determinist\u0026rdquo;). It means that I believe that the universe is unfolding according to some causality laws (many of which are not yet fully known), and that since the origin of the universe (e.g., the Big Bang), things have been evolving according to the only one possible chain of event. Naturally, the hard version of determinism leaves no room for free will (though the illusion of free will is important) and creates some issues when it comes to responsibility (again, a topic for another time).\n  Note that this position is not incompatible with a probabilistic view of the world (I am also a rather radical Bayesianist üòÅ). In this context, the probabilistic perspective is mostly a framework to describe uncertainty and hidden mechanisms. For instance, if I flip a coin, a probabilistic approach would be to consider that there is a 50/50 probability on the outcome. That said, if we manage to gather information on all the parameters (the starting position of the coin, the velocity and angle of the tossing, gravity, the weight distribution on the coin, its resistance to air, characteristics of air pressure, wind etc.), one could pretty much accurately predict what the outcome would be. In other words, the outcome is already \u0026ldquo;determined\u0026rdquo; once the coined has been tossed. That doesn\u0026rsquo;t mean that a probabilistic model is not convenient to describe it, especially when we don\u0026rsquo;t have access to all these parameters (or powerful enough models to integrate them).\nMany attempts have been made to attack determinism (and especially by people trying to defend the possibility of free will), and recent advances in physics have giving them a lot of ammunition (the most striking example being the - often misunderstood - usage of quantum uncertainty to explain randomness, free-will, consciousness, god and pretty much everything). Nonetheless, determinism is one of the simplest assumption that can be made regarding causality and evolution.\nThe future is now Determinism has one important consequence. As all events stem one from the others, in a unique chain of causal events, then if we know the exact state of the system (i.e., you know the state of all of the variables of the system) at one point in time, as well as the rules governing the system, we can predict with certainty the system\u0026rsquo;s state at the next point in time, at t+1. If we repeat the process, we know the state of the system at t+2, and so on, until the end of times.\nIn other words, the end of the universe is engraved in its beginning. The future is already contained in the now. The whole evolution of the universe is already \u0026ldquo;set\u0026rdquo;. Myself, writing this post, am an expected consequence of the combination of parameters of the universe\u0026rsquo;s origin.\n   Time as a computational limit of human understanding The past, and future, are merely but illusions. All the information (about what has been, and what will be) is already known (not known by an intelligent being, but in the sense that the information is existing, encapsulated within each frame of time) The evolution of the world is, in that regards, similar to that of a movie on a DVD. All the movie is there, at once. And a computer can read, and \u0026ldquo;experience\u0026rdquo; (as far as the phenomenological experience of a computer goes) all that information at once.\nYet we cannot. We have to watch it unfold over time. We are cognitively constrained in that fourth dimension of time. The perception of time passing appears as some limitation of our own cognitive systems: we have to spend one hour and a half in order to make sense of the information. We cannot process it \u0026ldquo;at once\u0026rdquo; (we cannot yet just download the movie into our brain, and experience it without watching it). Is time passing a feature (or limitation) of our understanding?\nCould we imagine (as a thought experiment) some other forms of being that are not constrained nor ever drifting onwards in the time dimension? Which, through their immensely greater cognitive abilities, are able to process a lot more information, which renders their prediction and inference of the near past and future very accurate, to a point where they are able to almost \u0026ldquo;move in time\u0026rdquo; (at least in short time ranges as the universe)\nTime as a computational limit of the cosmos One thing to note is that, in the DVD analogy, the watcher is external to the content. We are not talking about Gandalf\u0026rsquo;s experience of its own movie. Which then begs the question, who\u0026rsquo;s watching our universe?! (note that this is a logical fallacy used here as a joke; analogy is not homology).\n The Ancient of Days (William Blake, 1794).  But let\u0026rsquo;s go back to that \u0026ldquo;simulated universe\u0026rdquo; hypothesis that we started with, to try to integrate with it determinism and its consequence on time. When we play the sims, the sims do not really care about what the speed that we, external Humans, play the game. Their experience (albeit primitive, but you see my point) is dictated by the system (the game and the computer). To what extend it can computationally process the information.\nIt\u0026rsquo;s like when playing Minecraft (pardon my video games references). At the start of the game, one must first \u0026ldquo;generate\u0026rdquo; the world. This runs a procedural generation algorithm that spatially lays out and populates a world. This can take up to several minutes, depending on how much of a nerd you are (i.e., the specs of your computer). Following this example, if our universe is itself a simulation, could time be a consequence of some limitation of the system that \u0026ldquo;runs\u0026rdquo; it (or generates it - after all, maybe God is just waiting for our universe to complete building to be able to play his game of \u0026ldquo;Worldcraft\u0026rdquo; or, perhaps more appropriately, \u0026ldquo;Minehumans\u0026rdquo;), which might explain the particular nature of the time dimension in our typical environment.\n \"Riddles in the dark...\"  While these are fun thought experiments to ponder over, note that until there, I have mainly speculated about time as we phenomenologically experience it. I haven\u0026rsquo;t even touched on the possible relationship between the idea of time as a computational limit, and time as it conceived in modern theoretical physics (for instance, as a geometrical dimension of the time-space continuum that can be deformed and, potentially, navigated in). But for this, you\u0026rsquo;ll need to get me talking after more beers üçª\nCheers!\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1605225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605225600,"objectID":"2ca70da4494c0823bd66f41907e15c9f","permalink":"https://dominiquemakowski.github.io/post/2020-11-13-time_computational_limit/","publishdate":"2020-11-13T00:00:00Z","relpermalink":"/post/2020-11-13-time_computational_limit/","section":"post","summary":"Note: this is a thought-experiment, not to be taken too seriously.\nWe live in a simulated universe In his famous simulation argument, the transhumanist Bostrom (2003, 2011) posits that we are living in a computer-generated reality.","tags":["Reality","Time","Determinism","Transhumanism","Science fiction"],"title":"Time as a computational limit","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Statistics"],"content":" Introduction Many psychology fields require to extract individual scores, i.e., point-estimates (i.e., a single value) for a participant/patient, to be used as an index of something and later interpreted or re-used in further statistical analyses. This single index is often derived from several ‚Äútrials‚Äù. For instance, the reaction times in the condition A (let‚Äôs say, the baseline) will be averaged together, and the same will be done with the condition B. Finally, the difference between these two means will be used an the individual score for a given participant.\nHowever, we can intuitively feel that we lose a lot of information when averaging these scores. Do we deal appropriately with the variability related to individuals, conditions, or the noise aggravated by potential outliers? This is especially important when working with a limited amount of trials.\nWith the advent of recent computational advances, new easy-to-implement alternatives emerge. For instance, one can ‚Äúmodel‚Äù the effects at an individual level (e.g., the simplest case, for the two conditions paradigm described above, would be a linear regression with the condition as a unique predictor), and use the parameters of each model as individual scores (e.g., the ‚Äúslope‚Äù coefficient of the effect of the manipulation), rather than the raw mean. This opens up the possibility of including covariates and take into account other sources of known variability, which could lead to better estimates.\nHowever, individual models are also sensitive to outliers and noise. Thus, another possibility is to model the effects at the population level and, at the same time, at the individual level. This can be achieved by modelling the participants as a random factor in a mixed model. In this case, the individual estimates might benefit from the population estimates. In other words, the effects at the population level will ‚Äúconstrain‚Äù or ‚Äúguide‚Äù the estimation at an individual level to potentially limit extreme parameters.\nUnfortunately, the above method requires to have all the data at hand, to be able to fit the population model. This is often not the case in on-going acquisition, or in neuropsychological contexts, in which the practitioners simply acquire data for one patient, and have to compute individual scores, without having access to the detailed population data. Thus, an in-between alternative could make use of Bayesian models, in which the population effects (for instance, the mean effect of the condition) could be entered as an informative prior in the individual models to, again, ‚Äúguide‚Äù the estimation at an individual level and hopefully limit the impact of noise or outliers observations.\nIn this post, the aim is to compare these 4 methods (basic individual model - equivalent to using the raw mean, population model, individual model with informative priors) in recovering the ‚Äútrue‚Äù effects using a simulated dataset.\n Results Generate Data We generate several datasets in which we manipulate the number of participants, in which the score of interest is the effect of a manipulation as compared to a baseline condition. 20 trials per condition will be generated with a known ‚Äútrue‚Äù effect (the centre of the distribution from which the data is generated). Gaussian noise of varying standard deviation will be added to create a natural variability (See the functions‚Äô definition below).\nlibrary(tidyverse) library(easystats) data \u0026lt;- get_data(n_participants=1000, n_trials=20) results \u0026lt;- get_results(data)  Figure 1: Example of a dataset containing 20 participants (shown with different colors). As can be seen, we introduced modulations in the inter- and intra- individual variability.  We will then compare the scores obtained by each method to the ‚Äútrue‚Äù score of each participant by substracting them from one another. As such, for each method, we obtain the absolute ‚Äúdistance‚Äù from the true score.\n Fit model Contrast analysis will be applied to compare the different methods together.\nmodel \u0026lt;- lm(Diff_Abs ~ Method, data=results) modelbased::estimate_contrasts(model) %\u0026gt;% arrange(Difference) %\u0026gt;% mutate(Level1 = stringr::str_remove(Level1, \u0026quot;Diff_\u0026quot;), Level2 = stringr::str_remove(Level2, \u0026quot;Diff_\u0026quot;)) %\u0026gt;% select(Level1, Level2, Difference, CI_low, CI_high, p) ## Level1 | Level2 | Difference | CI | p ## ------------------------------------------------------------------------------------- ## IndividualModel_Priors | PopulationModel | -1.85e-03 | [-0.01, 0.01] | \u0026gt; .999 ## IndividualModel_Freq | PopulationModel | 1.70e-03 | [-0.01, 0.01] | \u0026gt; .999 ## IndividualModel_Freq | IndividualModel_Priors | 3.55e-03 | [-0.01, 0.01] | \u0026gt; .999  Visualize the results  Figure 2: Average accuracy of the different methods (the closest to 0 the better).   Figure 3: Accuracy depending on the number of total participants in the dataset.    Conclusion Though not significantly different, it seems that raw basic estimates (that rely only on the individual data) perform consistently worse than the population model or individual models informed by priors, especially for small datasets (between 10 and 100 participants) - though again, the difference is tiny in our simulated dataset. In the absence of the whole population dataset, it seems that using individual Bayesian model with informative priors (derived from the population model) is a safe alternative.\n Functions library(tidyverse) library(easystats) library(rstanarm) library(ggdist) # Get data ---------------------------------------------------------------- get_data \u0026lt;- function(n_participants = 10, n_trials = 20, d = 1.5, var = 3, noise = 0.1) { scores_baseline \u0026lt;- rnorm(n_participants, 0, 1) scores_condition \u0026lt;- rnorm(n_participants, d, 1) variances \u0026lt;- rbeta(n_participants, 2, 8) variances \u0026lt;- 0.1 + variances * (var / max(variances)) # Rescale noise_sd \u0026lt;- abs(rnorm(n_participants, 0, noise)) data \u0026lt;- data.frame() for (i in 1:n_participants) { a \u0026lt;- rnorm(n_trials, scores_baseline[i], variances[i]) b \u0026lt;- rnorm(n_trials, scores_condition[i], variances[i]) a \u0026lt;- a + rnorm(n_trials, 0, noise_sd[i]) # Add noise b \u0026lt;- b + rnorm(n_trials, 0, noise_sd[i]) # Add noise data \u0026lt;- rbind(data, data.frame( \u0026quot;Participant\u0026quot; = sprintf(\u0026quot;S%02d\u0026quot;, i), \u0026quot;Y\u0026quot; = c(a, b), \u0026quot;Score_True\u0026quot; = rep(c(scores_baseline[i], scores_condition[i]), each = n_trials), \u0026quot;Condition\u0026quot; = rep(c(\u0026quot;Baseline\u0026quot;, \u0026quot;Manipulation\u0026quot;), each = n_trials) )) } data } # Visualize data ----------------------------------------------------------- p \u0026lt;- get_data(n_participants = 20) %\u0026gt;% group_by(Participant, Condition) %\u0026gt;% mutate(mean = mean(Y)) %\u0026gt;% ggplot(aes(y = Y, x = Condition, fill = Participant, color = Participant, group = Participant)) + geom_line(aes(y = mean), position = position_dodge(width = 0.66)) + ggdist::stat_eye(point_interval = ggdist::mean_hdi, alpha = 0.66, position = position_dodge(width = 0.66), .width = c(0.95)) + ylab(\u0026quot;Score\u0026quot;) + theme_modern() + theme(legend.position = \u0026quot;none\u0026quot;) ggsave(\u0026quot;individual.png\u0026quot;, p, width = 7, height = 7, dpi = 450) # Get results ------------------------------------------------------------- get_results \u0026lt;- function(data) { # Raw method ---- results \u0026lt;- data %\u0026gt;% group_by(Participant, Condition) %\u0026gt;% summarise_all(mean) %\u0026gt;% rename(\u0026quot;Score_Raw\u0026quot; = \u0026quot;Y\u0026quot;) %\u0026gt;% arrange(Condition, Participant) %\u0026gt;% ungroup() # Population model ---- model \u0026lt;- lme4::lmer(Y ~ Condition + (1 + Condition | Participant), data = data) fixed \u0026lt;- insight::get_parameters(model, effects = \u0026quot;fixed\u0026quot;)$Estimate random \u0026lt;- insight::get_parameters(model, effects = \u0026quot;random\u0026quot;)$Participant # Transform coefs into scores pop_baseline \u0026lt;- random[, 1] + fixed[1] pop_manipulation \u0026lt;- pop_baseline + random[, 2] + fixed[2] results$Score_PopulationModel \u0026lt;- c(pop_baseline, pop_manipulation) # Individual model ---- individual_model_data \u0026lt;- data.frame() for (participant in unique(data$Participant)) { cat(\u0026quot;.\u0026quot;) # Print progress dat \u0026lt;- data[data$Participant == participant, ] # Frequentist model1 \u0026lt;- lm(Y ~ Condition, data = dat) nopriors \u0026lt;- parameters::parameters(model1)$Coefficient # Bayesian without priors # model2 \u0026lt;- stan_glm(Y ~ Condition, data = dat, refresh = 0) # bayes \u0026lt;- parameters::parameters(model2)$Median # Bayesian with Priors model3 \u0026lt;- stan_glm(Y ~ Condition, data = dat, refresh = 0, prior = normal(fixed[1]), prior_intercept = normal(fixed[2]) ) priors \u0026lt;- parameters::parameters(model3)$Median individual_model_data \u0026lt;- rbind( individual_model_data, data.frame( \u0026quot;Participant\u0026quot; = c(participant, participant), \u0026quot;Condition\u0026quot; = c(\u0026quot;Baseline\u0026quot;, \u0026quot;Manipulation\u0026quot;), \u0026quot;Score_IndividualModel\u0026quot; = c(nopriors[1], nopriors[1] + nopriors[2]), # \u0026quot;Score_IndividualModel_Bayes\u0026quot; = c(bayes[1], bayes[1] + bayes[2]), \u0026quot;Score_IndividualModel_Priors\u0026quot; = c(priors[1], priors[1] + priors[2]) ) ) } results \u0026lt;- merge(results, individual_model_data) # Clean output ---- diff \u0026lt;- results %\u0026gt;% mutate( # Diff_Raw = Score_True - Score_Raw, Diff_PopulationModel = Score_True - Score_PopulationModel, Diff_IndividualModel = Score_True - Score_IndividualModel, # Diff_IndividualModel_Bayes = Score_True - Score_IndividualModel_Bayes, Diff_IndividualModel_Priors = Score_True - Score_IndividualModel_Priors ) %\u0026gt;% select(Participant, Condition, starts_with(\u0026quot;Diff\u0026quot;)) %\u0026gt;% pivot_longer(starts_with(\u0026quot;Diff\u0026quot;), names_to = \u0026quot;Method\u0026quot;, values_to = \u0026quot;Diff\u0026quot;) %\u0026gt;% mutate(Diff_Abs = abs(Diff)) diff } # Analysis ---------------------------------------------------------------- results \u0026lt;- data.frame() for(n in seq.int(10, 300, length.out = 10)){ data \u0026lt;- get_data(n_participants = round(n), n_trials = 20) rez \u0026lt;- get_results(data) %\u0026gt;% select(-Participant) %\u0026gt;% group_by(Condition, Method) %\u0026gt;% summarise_all(mean) %\u0026gt;% mutate(n_Participants = n, Method = as.factor(Method), Dataset=paste0(\u0026quot;Dataset\u0026quot;, round(n, 2))) results \u0026lt;- rbind(results, rez) print(n) # Print progress } # model \u0026lt;- mgcv::gam(Diff_Abs ~ Method + s(n_Participants, by = Method), data = results) model \u0026lt;- lm(Diff_Abs ~ Method * poly(n_Participants, 3), data = results) parameters::parameters(model) contrasts \u0026lt;- modelbased::estimate_contrasts(model) %\u0026gt;% arrange(Difference) %\u0026gt;% mutate( Level1 = stringr::str_remove(Level1, \u0026quot;Diff_\u0026quot;), Level2 = stringr::str_remove(Level2, \u0026quot;Diff_\u0026quot;) ) %\u0026gt;% select(Level1, Level2, Difference, CI_low, CI_high, p) # Visualize results --------------------------------------------------------- p \u0026lt;- modelbased::estimate_means(model) %\u0026gt;% arrange(Mean) %\u0026gt;% mutate( Method = stringr::str_remove(Method, \u0026quot;Diff_\u0026quot;), Method = factor(Method, levels = Method) ) %\u0026gt;% ggplot(aes(x = Method, y = Mean, color = Method)) + geom_line(aes(group = 1)) + geom_pointrange(aes(ymin = CI_low, ymax = CI_high), size = 1) + theme_modern() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_color_material() ggsave(\u0026quot;featured.png\u0026quot;, p, width = 10, height = 6, dpi = 450) p \u0026lt;- modelbased::estimate_relation(model) %\u0026gt;% mutate(Method = stringr::str_remove(Method, \u0026quot;Diff_\u0026quot;)) %\u0026gt;% ggplot(aes(x = n_Participants, y = Predicted)) + geom_point(data=mutate(results, Method = stringr::str_remove(Method, \u0026quot;Diff_\u0026quot;)), aes(y=Diff_Abs, color = Method)) + geom_ribbon(aes(ymin=CI_low, ymax=CI_high, fill=Method), alpha=0.1) + geom_line(aes(color = Method), size=1) + theme_modern() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_color_material() + scale_fill_material() ggsave(\u0026quot;n_participants.png\u0026quot;, p, width = 10, height = 6, dpi = 450) # Save results ------------------------------------------------------------ d \u0026lt;- list(\u0026quot;results\u0026quot; = results, \u0026quot;model\u0026quot; = model, \u0026quot;contrasts\u0026quot; = contrasts) save(d, file = \u0026quot;data.Rdata\u0026quot;)  References You can reference this post as follows:\n- Makowski, D. (2020, September 14). How to extract individual scores from repeated measures. Retrieved from https://dominiquemakowski.github.io/post/individual_scores/\nThanks for reading! Do not hesitate to share this post, and leave a comment below ü§ó\nüê¶ And don‚Äôt forget to join me on Twitter [@Dom_Makowski](https://twitter.com/Dom_Makowski)\n ","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"c82f073184046aa2c80f32c16c767393","permalink":"https://dominiquemakowski.github.io/post/2020-09-14-individual_scores/","publishdate":"2020-09-14T00:00:00Z","relpermalink":"/post/2020-09-14-individual_scores/","section":"post","summary":"We compare different methods (individual models, Bayesian models with informative priors, random effects from mixed models) to extract individual scores from repeated measures tasks.","tags":["Statistics","R","Neuropsychology","Bayesian","Individual scores"],"title":"How to extract individual scores from repeated measures","type":"post"},{"authors":["Dominique Makowski"],"categories":["Neuropsychology",""],"content":"The place of neuropsychology Let\u0026rsquo;s make a simple experiment. Pick one young and brilliant neuropsychologist and ask \u0026ldquo;what is neuropsychology?\u0026rdquo;. In some cases, after a few seconds of hesitation, you could hear answers like \u0026ldquo;being a neuropsychologist means doing this or that\u0026rdquo;. In other cases, you might come across incomplete - or even false - responses, such as \u0026ldquo;neuropsychology is a tool\u0026rdquo;, \u0026ldquo;a method\u0026rdquo;, \u0026ldquo;a paradigm\u0026rdquo;, or even worse, \u0026ldquo;a point of view\u0026rdquo;.\nThat does not mean that our neuropsychologist is incompetent, far from it. But formally defining our field as a whole is not an exercise that we are used to do. Indeed, the training in neuropsychology usually comes in a fragmented way, little by little. A bit of cognitive neuroscience here, a bit of neuropsychological syndromes there, some cognitive tests administration over here, and some cortical neuroanatomy over there\u0026hellip; Though we might, in fine, acquire a global vision and understanding of neuropsychology, verbalizing it is seldom necessary.\nThe definition of neuropsychology is actually quite complex to formalize, and can even be hotly debated. The jobs and positions that stem out of this field are many, and practitioners often tend to circumscribe neuropsychology to their own activity. For instance, a neuropsychologist that mainly does cognitive rehabilitation with psychiatric patients might have quite a different vision from another that does, day after day, presurgical cognitive assessments. And that is without mentioning the neuropsychologists pursuing an academic career, or even the ones that have moved to the private sector.\nNo problem, would argue the careful reader, if the definitions are too narrow, let\u0026rsquo;s take more general one. It\u0026rsquo;s not that simple. Indeed, neuropsychology occupies a very particular place in the network of science, as it is at the crossroads between social sciences, biological sciences and medical fields. Giving a definition that is too large would lose its essence in the nebulous depths of neuroscience and psychology, which would be not be accurate; neuropsychologists, whether they are clinical practitioners or not, have a common training, a specific theoretical grounding, as well as a unique interpretation and analysis framework underpinned by a scientifically rigorous method. Taking these elements into account, I will attempt to give a simple, comprehensive and informative definition of neuropsychology.\nThe first axiom that we need to discuss is the notion of science. Is neuropsychology its \u0026ldquo;own\u0026rdquo; scientific field, or is it a mere portion of another one, such as cognitive neuroscience or psychology, which differs from other specializations only through its object of interest? \u0026ldquo;By science\u0026rdquo;, says Schopenhauer in his PhD thesis with a baroque title (On the Fourfold Root of the Principle of Sufficient Reason), \u0026ldquo;we understand a system of notions, i.e. a totality of connected, as opposed to a mere aggregate of disconnected, notions.\u0026quot; This definition applies well to neuropsychology, that contains a set of theories, hypotheses, methods and proofs feeding from one another and creating a coherent ensemble. As such, neuropsychology is its own scientific discipline, although a singular one\u0026hellip;\nIndeed, what is the \u0026ldquo;bigger\u0026rdquo; box in which neuropsychology fits? While neuropsychologists are often initially trained in psychology, one could argue that the focus on the brain makes it more belonging to neuroscience. Well, the organization and structure of Science is a complicated issue. However, the particularity of the topographical location of neuropsychology is quite apparent.\nOn the one hand, neuropsychology belongs to a cluster of sciences interested a specific biological organ: the brain. As such, neuropsychology is an integral part of neuroscience. On the other hand, neuropsychology is interested in the productions of the brain (e.g., thoughts, feelings and behaviours) with a focus on the cognitive level (analyzing things in terms of cognitive processes and mechanisms), which makes it also belonging to psychology. Moreover, one could argue that neuropsychology, through its integration of the study of what we are biologically, and who we are mentally, has been connected to, and used as evidence in, philosophy of mind debates (for instance, famous neuropsychological cases studied by Sacks, Ramachandran or Milner have been widely discussed by contemporary philosophers). Finally, contrary to many other domains, neuropsychology has also an applied, practical component, that can be used in clinical practice. This clinical aspect, registering neuropsychology withing medical fields, takes multiple forms, such as assessment, diagnostic or therapeutic care, and can be used with a wide variety of patients and illnesses. These multiple facets make the wealth of neuropsychology, which offers an exceptional freedom of practice.\nAs we have seen, neuropsychology is located at the centre of colliding galaxies of knowledge, such as neuroscience, psychology, medicine and philosophy. However, the fast development of neuropsychology is gradually leading to the creation of subcomponents within itself, corresponding to different practices and theoretical steps. And these clusters are themselves growing. For instance, clinical neuropsychology was historically focused on diagnostic cognitive assessments, but has recently expanded on the treatment-side of things, with innovations like cognitive training and rehabilitation. This underlines neuropsychology as a rapidly evolving field, moving its potential towards yet uncharted territories.\nThe fourfold structure of neuropsychology Neuropsychology is born from the convergence of cognitive neurology, with pioneers such as Broca and Wernicke (which made inferences about brain functioning based on the observations of patients with brain lesions) and psychologists such as Ribot (focusing on the organization and semiology of cognitive deficits). This history has shaped neuropsychology as a two-faced entity, with one experimental side dedicated to understand the relationship between brain and cognition (by using pathological cases or natural variability of neurocognitive characteristics), and one clinical aspect, focusing on bringing this knowledge to the benefit of the patients suffering from brain disorders.\nHowever, beyond these two pillars of neuropsychology, recent advances have outlined a more theoretical level of neuropsychology, dedicated to a high-level integration of the data at hand to elaborate general theories and interfacing them with evolutionary or philosophical principles. Similarly, a computational facet, referring to the operationalization of the functioning in statistical terms, starts to emerge as a pseudo-independent aspect, propelled by the regain of interest and focus on the methodological and statistical aspects of psychology and neuroscience.\nThis structure is not fixed, but driven by the evolution of the field. It is possible that new poles will emerge, or differentiate over time, until maybe they separate from - or create new clusters within - neuropsychology.\n The fourfold structure of neuropsychology.  The definition of neuropsychology Neuropsychology is a theoretical and practical science investigating the relationship between 1) the structure and functioning of the brain, and 2) cognitive processes and their related derivatives, such as thoughts, feelings and behaviours. It is organised in four interconnected and overlapping dimensions:\n Experimental neuropsychology studies the variability of the brain and cognition (whether from pathological origin or not) to test theories and models through empirical experimentation. Clinical neuropsychology uses theories and models about mental functioning to better detect and assess disorders and deficits, leading to a precise diagnostic and an adapted treatment. Computational neuropsychology transforms the data acquired through experiments and observation into logical or statistical models of mental functioning that are used to operationalize the processes at stake. Theoretical neuropsychology integrates the evidence to elaborate and develop unifying theories to address fundamental questions about mental functioning.  Neuropsychology is located at the crossroads between neuroscience and psychology, at the interface between theory and practice. Its practitioners, the neuropsychologists, are bound by a specific training, by unique theoretical and historical references, and are endowed with an analysis and interpretation framework backed by a rigorous and scientific investigation methodology.\nThanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nReferences  Nicolas, S., \u0026amp; Murray, D. J. (1999). Th√©odule Ribot (1839‚Äì1916), founder of French psychology: A biographical introduction. History of Psychology, 2(4), 277. Schopenhauer, A. (1813). On the Fourfold Root of the Principle of Sufficient Reason. PhD dissertation.  You can reference this post as follows:\n- Makowski, D. (2020, September 13). What is Neuropsychology?. Retrieved from https://dominiquemakowski.github.io/post/what_is_neuropsychology/\n","date":1599955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599955200,"objectID":"307c6836540eb5c8ed073bd753bb5a79","permalink":"https://dominiquemakowski.github.io/post/2020-09-13-what_is_neuropsychology/","publishdate":"2020-09-13T00:00:00Z","relpermalink":"/post/2020-09-13-what_is_neuropsychology/","section":"post","summary":"In which I discuss the place of neuropsychology in the galaxy of sciences, its structure and its definition.","tags":["Neuropsychology","Epistemology","Psychology","Definition"],"title":"What is neuropsychology?","type":"post"},{"authors":["Dominique Makowski"],"categories":["Psychology"],"content":" Disclaimer: I don\u0026rsquo;t have anything to do with GitHub, aside from being a simple user. This article is not an advertisement for it, but rather a perspective on the role of technical social networks in psychology.   I already mentioned in another post that technical aspects and skills will play an increasing role in psychology. This relationship isn\u0026rsquo;t by any means new. More than a century ago, pioneering psychologists were demonstrating formidable engineering and craftsmanship skills to build new tools and apparatuses to measure what they were interested in (see for instance Nicolas \u0026amp; Makowski, 2016). But years have gone by, and the digital revolution has happened. As a result, most of the \u0026ldquo;technical\u0026rdquo; aspects (a rather vague term covering everything that is not related to the semantic knowledge of psychological theories and facts) are now ultimately tied to software. Critically, your ability to use these softwares will determine the speed and ease at which you can achieve your goals and produce high quality assignments.\nAs an example, during my studies, most of the statistics course was delivered through the usage of one particular software (Statistica¬© ü§Æ). At the exam, your score didn\u0026rsquo;t much depend on your understanding of what a t-test is, when to use it or anything like that; but rather on your knowledge of the software, and your ability to click on the right buttons faster than your peers. While this is an unfortunate example that can be used to criticize the reliance on tools rather than fundamental knowledge, it also tells us something about the reality of the current world. In research, the better you are for instance at data processing (which involves both the knowledge of how to navigate the software and the knowledge of what to do in general), the faster you will be able to carry it out, and the less stressed you will be, resulting in a cascade of other positive outcomes (increased well-being, work-quality, productivity, opportunities, etc.).\nHowever, one common mistake is to delay learning new stuff (especially things outside our comfort zone) until we have no choice. This is understandable given that in the short term, certain skills may not be absolutely needed (i.e., you can manage without them) and acquiring them can be a steep learning curve (which can be hard, frustrating and effortful). However, you should start investing in your technical skills as soon as possible (as the time devoted to learning will only shrink as you advance) if you don\u0026rsquo;t want to become very close friends with pressure, stress, hatred, frustration and despair. So stay on the light side of the force and embrace the future.\n A psychology researcher realizing that he should have learned programming earlier.  And it\u0026rsquo;s not just about learning to use some software just for the sake of having things done and getting faster results. A lot of science is done through software, not only with them. People are actively discussing new methods, algorithms and tools that then expand like never before the possibilities of researchers. Flaming debates have been going on with frameworks and workflows clashing with thunderous sparks (for instance, Bayesian vs. frequentist statistics, ANOVAs vs. (mixed) regressions, etc.), and these calls for change find echo because of developments of software, allowing initiated users to test, validate and use new methods.\nOpen-access software It might not seem like it when you\u0026rsquo;re studying it at the university, but science is currently in the middle of a revolution. A massive paradigmatic change, partly fuelled by the growth of open-science, which covers aspects like open-access and open-source. This means, for software, that they are no longer being developed by private companies and sold for money. Instead, they are developed in a public fashion, and everybody is welcome to chime in and provide input, suggestions, report bugs or improve the code.\nOpen-source development means faster and better software, and more importantly, the creation of a true connection between developers and users. In fact, the former are often first and foremost also the latter, meaning that in a lot of cases (at least, mine üòÖ), people started writing a software because they needed it for their own personal job.\nBut the beauty lies in the fact that users can seemingly become developers too, or contributors, at the very least. Sometimes, users end up on a software development page to solve a bug or an issue that they encountered. From there, there can start following the developments, and getting involved. And not necessarily be writing code. It can be by answering to other issues, helping other users, reporting bugs and typos, improving the documentation, giving ideas and suggestions, testing new features and encouraging the developers. There are so many to contribute to the development and, as a result, become an active member of the open-science community. And moreover, doing so is also a great way to learn the theoretical bits. For instance, the most efficient way of learning the complexities of EEG acquisition and processing was to follow the development of an EEG-processing software (namely, MNE-Python). Reading issues that users encountered, and replies from experts and developers, trying to understand what functions do, what are the different parameters, what are the possibilities, the limits and so on.\nAll in all, engaging in open-source software is a great way to increase your technical expertise and get involved in the community of researchers. And who knows, you might meet cool people, create new connections, and that\u0026rsquo;s always great!\n Help making the first pane true.  Software as a social network Now that you\u0026rsquo;ve buckled up, ready to engage in open-source software, you might wonder; where does that happen? Ladies and gentlemen, let me introduce GitHub.\nSeveral years ago, when I was an undergrad student, I had to write a lot of stuff, such as for instance reports, project and theses. All of these documents went through several back and forths with supervisors, which made comments and modifications. But I was terribly afraid to remove some paragraph or sentence that I would need later on. As a result, I ended up in a hell in which my tormentors were named project.docx, project_v2.docx, project_v3.docx, project_v3_modifs.docx, project_v3_final.docx, project_v4_comments.docx, project_v4_final.docx, project_v4final2.docx, project_v4_finalfinal.docx. And what if my computer broke (that was before Dropbox)? I could lose everything üò±\nThis is when I heard about something called version control. Apparently, there was a system out there that allowed you to save all your modifications, and be able to go back at any point in time. This system was called git, and it was super obscure. However, I discovered that this system had a, online interface, in the form of a website, on which you can go and upload files and documents for free. This is how I discovered GitHub. And back in the days, it was really mostly used by programmers (because the nature of code makes it very suited for version control), a world I didn\u0026rsquo;t belong to.\n There several great alternatives go GitHub, like GitLab, BitBucket, etc., that might be just as good, if not better. The reason why I\u0026rsquo;m mainly talking about GitHub here is because this post is not about the intrinsic quality or features of these platforms for developers, but rather as a social network. An important part of any social network is its popularity and - as of for now - GitHub is the most popular.   I witnessed GitHub growing and becoming a true social network, improving its accessibility and user-friendliness. It is now more like a hub where all kinds of people gather to discuss software and technical bits, than a den for hairy geeks. There are also many users who are new to programming (e.g. researchers who are using software as a means to an end) and if you belong to this category of people, don\u0026rsquo;t underestimate your contribution to developers! Often it is such users that help developers improve user friendliness and identify code bugs (for example, when running the code on actual data sets). It is also used as a public technical portfolio, in which you can display your achievements, your projects and your interests. And while it was originally centred around programming, it has extended its audience quite a bit, and people are now using GitHub to store data (for instance the COVID-19 data), books, create websites (for instance, this website is stored on GitHub) or write scientific papers!\nThe reason why I\u0026rsquo;m writing this is because I know all too many young researchers, grappling with some software, struggling to find help, that are too shy to just contact the developers or the community. Just jump in there, create a public issue (instead of writing an email, so that your question will benefit future users). Most of the developers will be happy to help, and glad to see their software and code actually used by others.\nIn conclusion, go and dive into the world of open-science and open-source software, you\u0026rsquo;ll be on the right side of history. üòé\nWhat to do once you\u0026rsquo;re on GitHub At the very least, the very first step is to create an account. Even if you don\u0026rsquo;t use it now, it will be useful in the future (it shows that you are interested in technical stuff, it allows you to post issues and connect to other platforms, and support developers).\n Find a package / software that you like. Super biased suggestions include:  NeuroKit: a Python package for Neurophysiological Signal Processing bayestestR: an R package for Bayesian statistics correlation: an R package for correlations report: an R package to report statistics effectsize: an R package for effect sizes parameters: an R package for understanding statistical models performance: an R package for testing how good your model is   \u0026ldquo;Watch it\u0026rdquo; (the button in the top-right corner), so you\u0026rsquo;ll be notified of its activity Read the README file (the \u0026ldquo;front page\u0026rdquo;), check-out the issues, understand how to navigate the repository Engage with the developers, create an issue to report bugs or problems, or just to express support - developing a software takes time and effort, and is often done out of passion and for free. Words of encouragement are always appreciated ü§ó Create your own repository Make your own website  And if you want to learn how to use GitHub to make contributions, check-out our tutorial!\n Thanks for reading! Let me know if I forgot something by adding a comment below üëá\n","date":1590537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590537600,"objectID":"9611f20f48cb1435ddd92aac53335f9d","permalink":"https://dominiquemakowski.github.io/post/2020-05-27-github_psychologists/","publishdate":"2020-05-27T00:00:00Z","relpermalink":"/post/2020-05-27-github_psychologists/","section":"post","summary":"Top reasons why engaging into GitHub will give you the edge and benefit psychological science.","tags":["Github","Psychology","Programming","Psychologist","Open science"],"title":"Why psychologists should join GitHub","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Python","Psychology"],"content":"Many psychology students or researchers are faced with the challenge - or the opportunity - of learning a programming language. Which one should you learn?\nAs an ex- psych student and a daily user and developer of both, here\u0026rsquo;s my take on this hot debate.\nWhat has programming to do with psychology? If you\u0026rsquo;re a very young psychology student, or a future one, you might wonder: why the heck would I have to learn programming in psychology? \u0026ldquo;Psychology is like philosophy, it\u0026rsquo;s just learning how people\u0026rsquo;s minds work by reading books and overthinking stuff\u0026rdquo;. If you still think that, you\u0026rsquo;re in for one hell of a ride.\nPsychology is, since its very beginning, a hard and experimental science. The founding fathers of psychology were dedicated to find ways to objectively measure psychological phenomena and uncovering the mathematical laws that govern Human behaviour (one of the fields of psychology is even called psychophysics). This sciency nature has been toned down by the booming popularity of pseudo-scientific approaches like psychoanalysis, that contributed to the stereotypical public image of the shrink doodling while listening to a neurotic patient. But that\u0026rsquo;s a distorted and old-fashioned view, clearly not representative of the future of psychology.\nThe fact is that psychology is very closely connected with statistics. Many great statistical advances were made by psychologists, and all true psychological discoveries are backed by statistical findings. And this importance of statistics is - and will be - growing further, partly due to the recent realization of some major issues in the field due to improper statistical procedures (coined the \u0026ldquo;replicability crisis\u0026quot;). Moreover, psychology is more and more relying on advanced data-acquiring methods (smartphone apps, website data, physiological and brain recording devices like EEG, MRI, etc.). And these new formats often require specialized knowledge (web-scraping, database querying, neuroimaging, signal processing, machine learning, \u0026hellip;). Even in the most applied kind of clinical or psychotherapeutic specialization, where you\u0026rsquo;d think you\u0026rsquo;d be safe, they are starting to use data intensive methods like neuro-feedback, virtual reality or smartphone sensing and surveying.\nLong story short, no matter which branch of psychology you specialize in, you will be confronted with some technical aspects that won\u0026rsquo;t be able to solve with Excel. Importantly, these are the skills that will make the most difference between students, and that will matter a lot if you want to pursue research.\nSo, ready to dive into programming? Fear not! It\u0026rsquo;s not that complicated. Moreover, it\u0026rsquo;s one of the most rewarding skill you can develop. I can assure you that you won\u0026rsquo;t regret the time invested in learning it üòä\nBut where should you start?\nBoth R and Python This increasing relationship between psychology and statistics on the one hand, and other more general technical aspects on the other, is the reason why R and Python are so popular in psychology. Both languages are free, open-source, suited for beginners, and have a large base of users with a ton of learning material online. What\u0026rsquo;s the difference between them?\nPut simply, R is for statistics, Python is for the rest.\nSo why is there a virulent debate going on, and a choice to make? It\u0026rsquo;s true that I, in theory, would recommend learning both, as they are complementary and have their own strengths and weaknesses.\nHowever, many opinionated people arguing in favour of one or the other (usually the only one they know) will say that learning both is essentially a waste of time. They will put forth a strong argument: you can do whatever you do in R in Python, and vice-versa. In other words, both languages can be used to achieve your goals, and it\u0026rsquo;s better to specialize in one than have a limited knowledge of both.\nAlthough I do not agree with that statement, I do acknowledge that people have limited time and resources to learn. Saying \u0026ldquo;just learn both\u0026rdquo; is easy, but is arguably an unrealistic expectation for the vast majority of people. So why learning both can be a long-term goal (especially if you want to do research), you have to start somewhere. So, what starter language should you select?\n Ash choosing his starter programming language. He has the choice between R, Python and Bulbasaur, i.e, Matlab - the one that no one likes.  What about Matlab? There was a time when Matlab was the boss. It was used everywhere and had the best functionalities for neuroimaging, signal processing and maths. But that time is over. Matlab is already a dead language, which burial process will continue in the years to come. Why is it dead? Because it is expensive, closed, ugly, and most importantly the alternatives (namely R and Python) are now more powerful and featured than Matlab.\n Agamemnon reacting to king Priam saying \"The city of Matlab will never be conquered\".  The truth is, there are only two reasons people still use Matlab: habit (it\u0026rsquo;s hard to learn a new approach if your old way of doing things still works) and SPM (a toolbox for neuroimaging that is still - for now - the leader in the field).\nBut seriously, don\u0026rsquo;t waste time on it if you have limited resources, it\u0026rsquo;s just not worth it. You will learn an outdated tool that you won\u0026rsquo;t be able to use in another lab if they don\u0026rsquo;t agree to pay for an expensive license (unless you\u0026rsquo;re a pirate ‚ò†Ô∏è). Whereas with open and free languages like R or Python, you have access to the best tools and can use them freely everywhere. Also, it makes you a supporter of open-science, and that\u0026rsquo;s trendy üòÅ.\nHow to decide between R and Python Time has come to make a decision.\nDespite what people say, R and Python are not equivalent. You can argue as much as you want, but doing statistics and data visualization in Python is not as fast, easy and neat as it is in R. And signal processing or neuroimaging is not as powerful in R as compared to Python. Note that both languages are still growing and changing, and they are influencing themselves: for instance, many popular Python modules (e.g., pandas, statsmodels, seaborn, \u0026hellip;) have been directly inspired by R. As such, the boundaries between the two languages are fading (and I\u0026rsquo;m not even mentioning the great advances in interoperability, with tools like reticulate that allow you to use one language directly inside the other).\nThat being said, Python and R remain very different languages at their core, with a different feel and vibe to it. R was made by statisticians for statistics, and the majority of its users are academics and researchers. On the contrary, Python is a true general-purpose \u0026ldquo;programming\u0026rdquo; language, widely used outside of academia, in the private sector.\nHere are some things to consider when deciding on what language to learn:\nReasons to choose Python  You have some basic knowledge or familiarity with programming  For instance, you know what a loop is. Python being a true programming language, having any prior experience will be useful.\n You are good with logic and spatial representation (like imagining shapes in 3D, rotating them, etc.)  In Python, you will have to think with a \u0026ldquo;programming\u0026rdquo; mindset. That means perceiving things in terms of logical statements and blocks, understanding data as 2D or 3D tables that you have to slice and recombine.\n You are comfortable with maths  In Python, numbers and numbers combinations are used a lot. Paradoxically, you will typically see a lot more of maths in Python than in R.\n You plan to do signal processing or experimental tasks creation  These are some of the domains where Python is well-established (which doesn\u0026rsquo;t mean that R doesn\u0026rsquo;t have some great tools in development).\n You are good at googling and don\u0026rsquo;t mind spending time looking for the right answer  Python has so much material online that it\u0026rsquo;s sometimes hard to find the appropriate thing. Harder than in R, in my opinion.\nReasons to choose R  You have no experience with programming whatsoever  R is not made to be used as a traditional programming language. It\u0026rsquo;s more of finding what functions to apply to what, and that makes it easy for beginners.\n You are interested in statistical analyses, modelling things, and making inferences from data  R excels at this. You can create powerful models super easily and jump into their understanding and interpretation.\n You like making nice figures and plots  R, through the ggplot ecosystem, has hands down the best tools for visualization. Your imagination is the limit (check-out the artworks by Thomas Lin Pedersen abd Danielle Navarro üòç).\n You are not so good with stats or maths  You heard it right! To start with R you don\u0026rsquo;t need to know stats or maths like a boss. R, in fact, will help you to become proficient at it, by slowly opening more and more layers of complexity to you, if you are deemed worthy.\n You are interested in joining the academic community  Because most of its users are academics, R has a fantastic community online, for instance on Twitter #rstats.\nOther considerations  What your peers are learning  It\u0026rsquo;s easier to learn together, so try to discuss it with your class or lab mates if you can.\n What your lab is using  It might be easier if you have mentors that can understand what you are doing and guide you. But that should not be a priority, as it can lead to old habits reproduction (especially if your lab has a tradition of Matlab ü§≠).\nHands on! üëâ Looking for places to start? Check out this 10-min crash course introduction to Python and this collection of resources for R.\n Thanks for reading! üê¶ Don\u0026rsquo;t forget to join me on Twitter (@Dom_Makowski) and leave a comment below üëá\n","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"f737771fcdb72e3cc23418b44a768a27","permalink":"https://dominiquemakowski.github.io/post/2020-05-22-r_or_python/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/post/2020-05-22-r_or_python/","section":"post","summary":"Most psychology students or researchers are faced with the challenge of learning a programming language. Which one should you pick?","tags":["R","Python","Language","Psychology","Programming","Best language","Psychologist"],"title":"R or Python for Psychologists","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Statistics"],"content":"This is a very, very important topic given the widespread usage of reaction times in psychology. Most of the time, we analyze it as a regular variable, using traditional models such as linear models, ANOVAs etc. The problem is that these models assume that the RT is normally distributed, which is false.\nThis leads us to adjustements like outliers removal or log-transformation, distorting the data because of our non-appropriate models.\nThe good news is, it\u0026rsquo;s very easy to use better models, that account for the non-normal distribution of RT. And these alternatives are beautifully presented by Jonas K. Lindel√∏v in the guide below:\nüëâ Reaction time distributions: an interactive overview üëà\nIt is a must-read for all psychologist. Do check-it out!!\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ And don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1589760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760000,"objectID":"845c581aa213d2f946be410b800258d1","permalink":"https://dominiquemakowski.github.io/post/2020-05-18-analyze_rt/","publishdate":"2020-05-18T00:00:00Z","relpermalink":"/post/2020-05-18-analyze_rt/","section":"post","summary":"Most researchers use the normal distribution to model reaction times, but it's wrong! Discover how to perform a good analysis of RT data.","tags":["Statistics","R","Reaction time","RT"],"title":"How to correctly analyze reaction time (RT) data","type":"post"},{"authors":["Dominique Makowski"],"categories":["Python","NeuroKit"],"content":"Mandelbrot Set I wrote a small Python function to easily generate and plot a Mandelbrot set. This function is now available through the NeuroKit2 package, and can be used as follows:\nimport neurokit2 as nk nk.fractal_mandelbrot(show=True)  The Mandelbrot set is defined in the between -2 and 2 on the x (real) and y (imaginary) axes. Following that, the image can be cropped accodingly by changing the coordinates. Moreover, the colors can be tweaked by changing the the colormap (cmap).\nm = nk.fractal_mandelbrot(real_range=(-2, 0.75), imaginary_range=(-1.25, 1.25)) plt.imshow(m.T, cmap=\u0026quot;viridis\u0026quot;) plt.axis(\u0026quot;off\u0026quot;) plt.show()  Buddhabrot Set It is also possible to generate a Buddhabrot:\nb = nk.fractal_mandelbrot(size=1500, real_range=(-2, 0.75), imaginary_range=(-1.25, 1.25), buddha=True, iterations=200) plt.imshow(b.T, cmap=\u0026quot;gray\u0026quot;) plt.axis(\u0026quot;off\u0026quot;) plt.show()  Added the option to return a so-called \u0026#39;Buddhabrot\u0026#39;üßò Amazing to see these shapes emerging from such a simple formula ü§Ø #fractalart pic.twitter.com/7nzxsvQa6R\n\u0026mdash; Dominique Makowski üßô (@Dom_Makowski) May 7, 2020  Althoug the NeuroKit Python package is primarily devoted at physiological signal processing, in also includes tons of other useful features.\nüëâ Discover more about NeuroKit here üëà\nHave fun!\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1589587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589587200,"objectID":"24e0e1cbe6d2139a2db8ef31500013c5","permalink":"https://dominiquemakowski.github.io/post/2020-05-16-python_mandelbrot/","publishdate":"2020-05-16T00:00:00Z","relpermalink":"/post/2020-05-16-python_mandelbrot/","section":"post","summary":"Create a Mandelbrot or Buddhabrot fractal in Python using NeuroKit.","tags":["Python","Fractal","Mandelbrot","Buddhabrot","NeuroKit"],"title":"One Python code line for a Mandelbrot fractal","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Statistics"],"content":"TLDR; BayestestR currently uses a 89% threshold by default for Credible Intervals (CI). Should we change that? If so, by what? Join the discussion here.\nMagical numbers, or conventional thresholds, have bad press in statistics, and there are many of them. For instance, .05 (for the p-value), or the 95% range for the Confidence Interval (CI). Indeed, why 95 and not 94 or 90?\nüëâ Read my complete post on the easystats' blog üëà\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\n","date":1589500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589500800,"objectID":"cf2561f214957332336b0c5696669283","permalink":"https://dominiquemakowski.github.io/post/2020-05-15-defence_ci95/","publishdate":"2020-05-15T00:00:00Z","relpermalink":"/post/2020-05-15-defence_ci95/","section":"post","summary":"The one where I discuss arguments in favour of 95% instead of alternatives like 90 or 89%.","tags":["Statistics","Confidence Interval","Credible Interval","CI"],"title":"In defence of the 95% CI","type":"post"},{"authors":["Dominique Makowski"],"categories":["R","Statistics"],"content":"You are a student or a researcher interested in Bayesian statistics and R? But all the tutorials and courses that you have found are too intimidating?\nFear no more!\nWith the easystats team, we have created a very gentle and introductory course for beginners.\nYou can find the link here:\nüëâ Get Started with Bayesian Statistics using R üëà\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1589414400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589414400,"objectID":"72db0e40cc612dd9c00b366f8a08c4aa","permalink":"https://dominiquemakowski.github.io/post/2020-05-14-intro_bayestestr/","publishdate":"2020-05-14T00:00:00Z","relpermalink":"/post/2020-05-14-intro_bayestestr/","section":"post","summary":"A gentle introduction to Bayesian statistics with R for people not familiar with any of these.","tags":["Bayes","R","Stats","BayestestR","Tutorial"],"title":"Introduction to Bayesian statistics with R","type":"post"},{"authors":["Dominique Makowski"],"categories":["Art","Neuroscience"],"content":"The main source for visual illusions Welcome to my illusion website!https://t.co/1DJIwbj0P9 pic.twitter.com/SYiK0JvJJl\n\u0026mdash; Akiyoshi Kitaoka (@AkiyoshiKitaoka) April 23, 2020  Comic A perceptual illusion walks into the bar... pic.twitter.com/svD1rtRcpT\n\u0026mdash; Jay Van Bavel (@jayvanbavel) August 18, 2020  Illusion of deformation Another amazing illusion from the amazing @jagarikin: The ring on the left seems to be bigger and expanding, the one on the right smaller and contracting... but they\u0026#39;re both the same size and neither is expanding or contracting at all. üòÆ pic.twitter.com/dchwX994PG\n\u0026mdash; Steve Stewart-Williams (@SteveStuWill) August 16, 2020  Illusion of rotation ÂõûËª¢„Åó„Å¶Ë¶ã„Åà„Åü„ÇâRT pic.twitter.com/WBoG7rAD2f\n\u0026mdash; „Åò„ÇÉ„Åå„Çä„Åç„Çì (@jagarikin) July 24, 2020  Illusion of colour Both people are the same colour in all three panels - an effect called \u0026#39;colour constancy\u0026#39; pic.twitter.com/CacNuJo54H\n\u0026mdash; Gavin Buckingham (@DrGBuckingham) July 4, 2020  Illusion of sound escalation Something about the continous fall here reminded me of thishttps://t.co/ABeEmdXeNK\n\u0026mdash; Amogha Udupa (@amg_omg) July 3, 2020  Illusion of movement angle The curveball illusion\nThe ball is falling straight down, but try not looking directly at it pic.twitter.com/ydJlzfZb0F\n\u0026mdash; „Äà Berger |üéÉ| Dillon „Äâ (@InertialObservr) July 2, 2020  Illusion of shape When you fixate on the yellow point, do you see dark triangles connecting the discs to the yellow point? Thanks to @Pascallisch, my old broken movie of the \u0026quot;spokes illusion\u0026quot; has been fixed. pic.twitter.com/edvLLXcShO\n\u0026mdash; Alex Holcombe (@ceptional) July 3, 2020  Illusion of deformation None of these lines are any more spikey than the others - really powerful illusion by Takahashi (2017) pic.twitter.com/Xr8ncWNNGE\n\u0026mdash; Gavin Buckingham (@DrGBuckingham) July 1, 2020  Illusion of colour In a classic visual illusion, two identical dots look very dissimilar against backgrounds of different colors. A new BCS-led study suggests that this visual processing takes place outside the brain‚Äôs visual cortex, possibly within the retina. https://t.co/D2NIZJUEye pic.twitter.com/WrfE4qTmOh\n\u0026mdash; Massachusetts Institute of Technology (MIT) (@MIT) June 17, 2020  Illusion of different rotation direction If this does not mess with your visual system, I don\u0026#39;t know what will... pic.twitter.com/vwxATYx39x\n\u0026mdash; Tim Kietzmann (@TimKietzmann) June 15, 2020  Illusion of different luminance Both pears are the same colour and luminance, despite one seeming brighter than the other pic.twitter.com/KkUJlTI82R\n\u0026mdash; Gavin Buckingham (@DrGBuckingham) May 17, 2020  Illusion of a \u0026lsquo;light-like\u0026rsquo; brightness And as I have tweeted before, your pupil actually constricts when you look at this illusion, just as it would if you looked at a bright light. Here\u0026#39;s a paper looking at this phenomenon. It\u0026#39;s a wonderful illusion.https://t.co/EAxK4hGLAH https://t.co/aClvekrSN6\n\u0026mdash; Mel_Goodale (@action_brain) May 17, 2020  Illusion of deformation „Äå„Çµ„ÇØ„É©„ÇΩ„Ç¶„ÅÆ‰∏ò„Äç\nThe checker pattern is aligned vertically and horizontally, but the image appears to bulge out. pic.twitter.com/CyCmTPYaDz\n\u0026mdash; Akiyoshi Kitaoka (@AkiyoshiKitaoka) April 14, 2020  Illusion of colour This is a black and white photograph. Only the lines have colour.\nWhat you ‚Äúsee‚Äù is what your üß† predicts the reality to be, given the imperfect information it gets. pic.twitter.com/gwttlcC2Zw\n\u0026mdash; Lionel Page (@page_eco) July 27, 2019  Illusion of deformation Adding small crosses at each intersection makes this perfectly normal grid all wonky! pic.twitter.com/DONyCqyh9A\n\u0026mdash; Gavin Buckingham (@DrGBuckingham) April 11, 2020  Illusion of different movement speed Interesting illusion. The upper rectangle appears to be moving faster. https://t.co/LI9Eh7vezy\n\u0026mdash; Mel_Goodale (@action_brain) April 7, 2020  Illusion of different rotation direction Rings appear to rotate clockwise, though they actually rotate counterclockwise.\n(a demo of \u0026quot;reversed phi\u0026quot; produced with phenomenal phenomena) pic.twitter.com/NyfTd12eAl\n\u0026mdash; Akiyoshi Kitaoka (@AkiyoshiKitaoka) April 2, 2020  Illusion of movement Extremely strong effect. One of the best I‚Äôve seen https://t.co/hCK0URgWrd\n\u0026mdash; Thomas Lin Pedersen (@thomasp85) February 15, 2020  Illusion of different size I\u0026#39;m biased here, but this is one of the strongest visual illusions I have ever seen.\nNone of the colored lines are moving. pic.twitter.com/QcW3u6WFB4\n\u0026mdash; Chris Said (@Chris_Said) January 3, 2020  Illusion of colour Stare at the centre and see green which is never there! pic.twitter.com/kHys53GbUz\n\u0026mdash; Gavin Buckingham (@DrGBuckingham) September 15, 2019  Illusion of different luminance The word \u0026quot;Gray\u0026quot; is always exactly the same shade of gray. pic.twitter.com/KYhk3xE0r5\n\u0026mdash; Robert Volcic (@VolcicR) June 18, 2019   Do you know other cool visual illusions? Let me know in the comments below! ü§ó\nThanks for reading! Do not hesitate to tweet and share this post and don\u0026rsquo;t forget to join me on Twitter üê¶ @Dom_Makowski\n","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760000,"objectID":"c37840885771f64362c79a19b7a04f85","permalink":"https://dominiquemakowski.github.io/post/2020-05-13-visual_illusions/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/post/2020-05-13-visual_illusions/","section":"post","summary":"Visual illusions are a fascinating phenomenon, being both artistic and informative on how the brain works. Here you will find a compilation of some of the mind-blowing optical illusions.","tags":["Optical illusions","Visual illusions","Art","Neuroscience","Perception","Predictive coding"],"title":"A compilation of the best visual illusions","type":"post"},{"authors":["Dominique Makowski"],"categories":["Academia"],"content":" Every. Damn. Time. pic.twitter.com/Bs8NzSLz00\n\u0026mdash; Dan Quintana (@dsquintana) July 17, 2020   it me during my postdoc pic.twitter.com/KKgXXntsL1\n\u0026mdash; Dr. Stevie Chancellor (@snchancellor) January 9, 2020   my plans 2020 pic.twitter.com/n3vlR1Tcfo\n\u0026mdash; John Borghi (@JohnBorghi) May 20, 2020   Academics looking for happiness be like... https://t.co/dR3ZUQsJ7G\n\u0026mdash; josh grubbs (@JoshuaGrubbsPhD) May 13, 2020   Hi everyone, here\u0026#39;s some quality content to brighten your day: pic.twitter.com/RrxgKf5tpg\n\u0026mdash; Nathaniel Haines (@Nate__Haines) March 13, 2020   When you go to a conference and only know one other person pic.twitter.com/eHJEVKlH2Z\n\u0026mdash; David Howard (@Used_For_Glue) January 13, 2020   What every submission site should have pic.twitter.com/0AhenF0aB5\n\u0026mdash; PHD Comics (@PHDcomics) December 17, 2019   The postdoc to PI transition: https://t.co/wzqB5nBcpm\n\u0026mdash; Mike Feigin (@mikefeigin) December 16, 2019   Reading stats twitter. pic.twitter.com/8dLyCBoTbM\n\u0026mdash; Dani√´l Lakens (@lakens) November 25, 2019   Scientist: carefully designs experiment\nParticipant:https://t.co/1a8FqbfCZc\n\u0026mdash; Lionel Page (@page_eco) November 27, 2019   ‚ÄúAs requested by the reviewer, we double-checked the page numbers for each of our references‚Äù pic.twitter.com/9a4y1SGlEh\n\u0026mdash; Dan Quintana (@dsquintana) November 17, 2019   pic.twitter.com/hlfDFOIt5L\n\u0026mdash; Dr. Jess Hartnett üìä (@Notawful) October 26, 2019   Publisher: \u0026quot;unless we charge USD 10,000 per article, we won\u0026#39;t be able to survive\u0026quot;\nResearchers: pic.twitter.com/oh2i4i4KdI\n\u0026mdash; Dr. Alejandro Montenegro (@aemonten) October 25, 2019   when double-blind peer review isn\u0026#39;tpic.twitter.com/POYerkoHtw\n\u0026mdash; Chaz Firestone (@chazfirestone) October 17, 2019   For my upcoming 2-day R workshop. pic.twitter.com/cJjmqi2aLp\n\u0026mdash; Darren Dahly, PhD (@statsepi) November 7, 2016   Me post submission proofing and finding mistakes everywhere @AcademicChatter #academictwitter\npic.twitter.com/WB2gkft53t\n\u0026mdash; Sam Westwood (@westwoodsam1) October 16, 2019   Buying a high spec computer to run t-tests pic.twitter.com/DQvlDUtAzh\n\u0026mdash; Dan Quintana (@dsquintana) October 5, 2019   Moving a figure in Word pic.twitter.com/ef7ctQn3R4\n\u0026mdash; Dr. Alejandro Montenegro (@aemonten) September 15, 2019   Academics: read the syllabus\nAlso academics: did you send that to me already, I get a lot of emails, I didn\u0026#39;t read it, what did it say, can you send it again pic.twitter.com/xFaOwV9Z9h\n\u0026mdash; Dr Meryl Kenny (@merylkenny) September 12, 2019   when your deep learning model is literally just a logistic regression pic.twitter.com/YB1j1qqML0\n\u0026mdash; üî• Kareem Carr üî• (@kareem_carr) August 29, 2019   How reimbursements in academia work: pic.twitter.com/XWEtz3rfXO\n\u0026mdash; Dr. Dani Beck (@_DaniBeck) August 22, 2019   üêø: Me\nüåº: a sufficiently large sample size pic.twitter.com/W5ypnRbzhS\n\u0026mdash; Chelsea Parlett-Pelleriti (@ChelseaParlett) August 1, 2019   manuscript_submission.mp4 pic.twitter.com/rkyJE1FbF5\n\u0026mdash; Dan Quintana (@dsquintana) October 21, 2018   Me, looking into the psychometrics literature to see if they\u0026#39;ve any analysis insights I should be using pic.twitter.com/2HYDmM3E7J\n\u0026mdash; Tom Stafford (@tomstafford) July 26, 2019   Stack Overflow releases its own keyboard. pic.twitter.com/Nw7ts0Rf4V\n\u0026mdash; Khalil (@sehnaoui) June 21, 2019   \u0026quot;There\u0026#39;s free food at this conference\u0026quot;\nMe: pic.twitter.com/DMsXarXqRz\n\u0026mdash; Dr. Dani Beck (@_DaniBeck) May 24, 2019   this is upsettingly accurate pic.twitter.com/QLKIIYSVkf\n\u0026mdash; Rebecca Buxton (@RebeccaBuxton) April 26, 2019   Characterising today\u0026#39;s attempts at trying to do research: pic.twitter.com/qhS3ydehk6\n\u0026mdash; Jon Tennant (@Protohedgehog) February 13, 2019   #rstats #rstatsmemes pic.twitter.com/MZBNvVseeO\n\u0026mdash; R Memes for Statistical Fiends (@rstatsmemes) September 25, 2018   Do you know other funny tweets? Let me know in the comments below! ü§ó\nThanks for reading! Do not hesitate to tweet and share this post and don\u0026rsquo;t forget to join me on Twitter üê¶ @Dom_Makowski\n","date":1589241600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760000,"objectID":"364c7ce8797426ecb13589b571dc5c42","permalink":"https://dominiquemakowski.github.io/post/2020-05-12-funny_academic/","publishdate":"2020-05-12T00:00:00Z","relpermalink":"/post/2020-05-12-funny_academic/","section":"post","summary":"Some funny stuff only academics will get.","tags":["Funny","Academic life","Academia","Research","memes"],"title":"The funniest academic tweets","type":"post"},{"authors":["Dominique Makowski"],"categories":["Python","NeuroKit","Biosignals"],"content":"Create a natural ECG signal Generating artificial physiological signals can be very useful to build, test your analysis pipeline or develop and validate a new algorithm.\nGenerating a synthetic, yet realistic, ECG signal in Python can be easily achieved with the ecg_simulate() function available in the NeuroKit2 package.\nIn the example below, we will generate 8 seconds of ECG, sampled at 200 Hz (i.e., 200 points per second) - hence the length of the signal will be 8 * 200 = 1600 data points. We can also specify the average heart rate, although note that there will be some natural variability (which is a good thing, because it makes it realistic).\nimport neurokit2 as nk # Load the package simulated_ecg = nk.ecg_simulate(duration=8, sampling_rate=200, heart_rate=80) nk.signal_plot(simulated_ecg, sampling_rate=200) # Visualize the signal     The simulation is based on the ECGSYN algorithm (McSharry et al., 2003).\nHowever, for fast and stable results (as the realistic algorithm naturally generates some variability), one can approximate the QRS complex by a Daubechies wavelet. An ECG based on this method can also be obtained in NeuroKit by changing the method as follows:\nsimulated_ecg = nk.ecg_simulate(duration=8, sampling_rate=200, method=\u0026quot;daubechies\u0026quot;) nk.signal_plot(simulated_ecg, sampling_rate=200)     While faster and stable, the generated ECG is far from being realistic.\nüëâ Discover more about NeuroKit here üëà\nHave fun!\nReferences McSharry, P. E., Clifford, G. D., Tarassenko, L., \u0026amp; Smith, L. A. (2003). A dynamical model for generating synthetic electrocardiogram signals. IEEE transactions on biomedical engineering, 50(3), 289-294.\n Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below ü§ó\nüê¶ Don\u0026rsquo;t forget to join me on Twitter @Dom_Makowski\n","date":1558051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558051200,"objectID":"564a3fc66e3012f1a0c6616b45687679","permalink":"https://dominiquemakowski.github.io/post/2019-05-17-simulate_ecg/","publishdate":"2019-05-17T00:00:00Z","relpermalink":"/post/2019-05-17-simulate_ecg/","section":"post","summary":"Simulate a synthetic but realistic ECG signal in Python using NeuroKit.","tags":["Python","NeuroKit","ECG","EKG","Simulate","Artificial","Physiological","Biosignals"],"title":"Generate an articial ECG signal in Python","type":"post"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://dominiquemakowski.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"de6dae831e3352a894a2922d3119c167","permalink":"https://dominiquemakowski.github.io/cv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1855baad50cde30ad574d27f6ff6a4ef","permalink":"https://dominiquemakowski.github.io/dominiquemakowski/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dominiquemakowski/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9a71cca745ec70e27cd86aff678e9a08","permalink":"https://dominiquemakowski.github.io/project/cognitivecontrol/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/cognitivecontrol/","section":"project","summary":"A neuropsychological task measuring different aspects of cognitive control (processing speed, inhibition, conflict resolution...)","tags":["Python","Neuropsychology"],"title":"Cognitive Control","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f66be18173afe3a01308b7b76a636350","permalink":"https://dominiquemakowski.github.io/project/easystats/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/easystats/","section":"project","summary":"A collection of R packages to make the usage statistics and the implementation of good practices easy","tags":["R","Statistics"],"title":"easystats","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"10076164c1edc01c80ef90f862d5cf13","permalink":"https://dominiquemakowski.github.io/project/music/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/music/","section":"project","summary":"Piano arrangements and scores","tags":null,"title":"Music","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b1d532d62aa5089478581d97d951945e","permalink":"https://dominiquemakowski.github.io/project/neurokit/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/neurokit/","section":"project","summary":"A Python toolbox for neurophysiological signal processing","tags":["Python"],"title":"NeuroKit","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e6c410317866b17585fe664584bbc08d","permalink":"https://dominiquemakowski.github.io/project/neuropsydia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/neuropsydia/","section":"project","summary":"A Python module for creating experiments, tasks and questionnaires","tags":["Python","Neuropsychology"],"title":"Neuropsydia","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ebcf8ceac7154932f8e0c243aa360c8c","permalink":"https://dominiquemakowski.github.io/project/patientassessmentapp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/patientassessmentapp/","section":"project","summary":"A web application to facilitate the neuropsychological assessment of patients","tags":["R","Neuropsychology"],"title":"Patient Assessment","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa2c6ea6e64b8013bd8e57962f6d1563","permalink":"https://dominiquemakowski.github.io/project/pyllusion/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/pyllusion/","section":"project","summary":"A Python module for generating visual illusions","tags":["Python"],"title":"Pyllusion","type":"project"}]