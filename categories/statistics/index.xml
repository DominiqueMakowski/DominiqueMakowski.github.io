<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics | Dr Dominique Makowski</title>
    <link>https://dominiquemakowski.github.io/categories/statistics/</link>
      <atom:link href="https://dominiquemakowski.github.io/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 14 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dominiquemakowski.github.io/images/icon_hud75d04f2b1977d0bc7efdcf2aeb84fcd_760423_512x512_fill_lanczos_center_2.png</url>
      <title>Statistics</title>
      <link>https://dominiquemakowski.github.io/categories/statistics/</link>
    </image>
    
    <item>
      <title>How to extract individual scores from repeated measures</title>
      <link>https://dominiquemakowski.github.io/post/individual_scores/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://dominiquemakowski.github.io/post/individual_scores/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Many psychology fields require to extract individual scores, i.e., point-estimates (&lt;em&gt;i.e.&lt;/em&gt;, a single value) for a participant/patient, to be used as an index of something and later interpreted or re-used in further statistical analyses. This single index is often derived from several “trials”. For instance, the reaction times in the condition A (let’s say, the baseline) will be &lt;strong&gt;averaged&lt;/strong&gt; together, and the same will be done with the condition B. Finally, the difference between these two means will be used an the &lt;strong&gt;individual score&lt;/strong&gt; for a given participant.&lt;/p&gt;
&lt;p&gt;However, we can intuitively feel that we &lt;strong&gt;lose a lot of information&lt;/strong&gt; when averaging these scores. Do we deal appropriately with the variability related to individuals, conditions, or the noise aggravated by potential outliers? This is especially important when working with a limited amount of trials.&lt;/p&gt;
&lt;p&gt;With the advent of recent computational advances, new easy-to-implement alternatives emerge. For instance, &lt;strong&gt;one can “model” the effects at an individual level&lt;/strong&gt; (e.g., the simplest case, for the two conditions paradigm described above, would be a linear regression with the condition as a unique predictor), and use the &lt;strong&gt;parameters&lt;/strong&gt; of each model as individual scores (e.g., the “slope” coefficient of the effect of the manipulation), rather than the raw mean. This opens up the possibility of including covariates and take into account other sources of known variability, which could lead to better estimates.&lt;/p&gt;
&lt;p&gt;However, individual models are also sensitive to outliers and noise. Thus, another possibility is to &lt;strong&gt;model the effects at the population level&lt;/strong&gt; and, &lt;em&gt;at the same time&lt;/em&gt;, at the individual level. This can be achieved by modelling the participants as a &lt;strong&gt;random factor in a mixed model&lt;/strong&gt;. In this case, the individual estimates might benefit from the population estimates. In other words, the effects at the population level will “constrain” or “guide” the estimation at an individual level to potentially limit extreme parameters.&lt;/p&gt;
&lt;p&gt;Unfortunately, the above method requires to have all the data at hand, to be able to fit the population model. This is often not the case in on-going acquisition, or in neuropsychological contexts, in which the practitioners simply acquire data for one patient, and have to compute individual scores, without having access to the detailed population data. Thus, an in-between alternative could make use of &lt;strong&gt;Bayesian models&lt;/strong&gt;, in which the population effects (for instance, the mean effect of the condition) could be entered as a &lt;strong&gt;prior&lt;/strong&gt; in the individual models to, again, “guide” the estimation at an individual level and hopefully limit the impact of noise or outliers observations.&lt;/p&gt;
&lt;p&gt;In this post, the aim is to compare these 4 methods (raw mean, individual model, population model, individual model with priors) in recovering the “true” effects using a simulated dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;div id=&#34;generate-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Generate Data&lt;/h4&gt;
&lt;p&gt;We generate several datasets with varying random noise in which the score of interest is the effect of a manipulation as compared to a baseline condition. 20 trials per condition will be generated for 1000 participants with a known “true” effect. Gaussian noise of varying standard deviation will be added to create a natural variability (See the functions’ definition below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(easystats)

data &amp;lt;- get_data(n_participants=1000, n_trials=20, d=1, var=4, noise=0.33)
results &amp;lt;- get_results(data)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;individual.png&#34; alt=&#34;*Example of a dataset containing 20 participants (shown with different colors). As can be seen, we introduced modulations in the inter- and intra- individual variability.*&#34; width=&#34;1575&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: &lt;em&gt;Example of a dataset containing 20 participants (shown with different colors). As can be seen, we introduced modulations in the inter- and intra- individual variability.&lt;/em&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We will then compare the scores obtained by each method to the “true” score of each participant by substracting them from one another. As such, for each method, we obtain the absolute “distance” from the true score.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Fit model&lt;/h4&gt;
&lt;p&gt;Contrast analysis will be applied to compare the different methods together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- lm(Diff_Abs ~ Method, data=results)

modelbased::estimate_contrasts(model) %&amp;gt;%
  arrange(Difference) %&amp;gt;%
  mutate(Level1 = stringr::str_remove(Level1, &amp;quot;Diff_&amp;quot;),
         Level2 = stringr::str_remove(Level2, &amp;quot;Diff_&amp;quot;)) %&amp;gt;% 
  select(Level1, Level2, Difference, CI_low, CI_high, p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    Level1                 Level2    Difference      CI_low
## 1  IndividualModel_Priors                    Raw -6.530961e-03 -0.02880842
## 2         PopulationModel                    Raw -5.105364e-03 -0.02738282
## 3  IndividualModel_Priors        PopulationModel -1.425597e-03 -0.02370305
## 4    IndividualModel_Freq                    Raw -3.191891e-16 -0.02227746
## 5   IndividualModel_Bayes                    Raw  4.476532e-05 -0.02223269
## 6   IndividualModel_Bayes   IndividualModel_Freq  4.476532e-05 -0.02223269
## 7    IndividualModel_Freq        PopulationModel  5.105364e-03 -0.01717209
## 8   IndividualModel_Bayes        PopulationModel  5.150130e-03 -0.01712733
## 9    IndividualModel_Freq IndividualModel_Priors  6.530961e-03 -0.01574650
## 10  IndividualModel_Bayes IndividualModel_Priors  6.575726e-03 -0.01570173
##       CI_high p
## 1  0.01574650 1
## 2  0.01717209 1
## 3  0.02085186 1
## 4  0.02227746 1
## 5  0.02232222 1
## 6  0.02232222 1
## 7  0.02738282 1
## 8  0.02742759 1
## 9  0.02880842 1
## 10 0.02885318 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-the-means&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize the means&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;means &amp;lt;- modelbased::estimate_means(model) %&amp;gt;%
  arrange(Mean) %&amp;gt;%
  mutate(Method = stringr::str_remove(Method, &amp;quot;Diff_&amp;quot;),
         Method = factor(Method, levels=Method))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;means %&amp;gt;%
  ggplot(aes(x=Method, y=Mean, color=Method)) +
  geom_line(aes(group=1)) +
  geom_pointrange(aes(ymin=CI_low, ymax=CI_high), size=1) +
  theme_modern() + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  scale_color_material(palette=&amp;quot;rainbow&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dominiquemakowski.github.io/post/individual_scores/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Though not significant, using the whole population model seems the most robust option when the whole dataset is available. Otherwise, using an individual model with informative priors (derived from the population model) appears as a good alternative.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Functions&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(easystats)
library(rstanarm)
library(ggdist)


# Get data ----------------------------------------------------------------



get_data &amp;lt;- function(n_participants=10, n_trials=20, d=1, var=3, noise=0){

  scores_baseline &amp;lt;- rnorm(n_participants, 0, 1)
  scores_condition &amp;lt;- rnorm(n_participants, d, 1)
  variances &amp;lt;- rbeta(n_participants, 2, 8)
  variances &amp;lt;- 0.1 + variances * (var / max(variances))  # Rescale
  noise_sd &amp;lt;- abs(rnorm(n_participants, 0, noise))

  data &amp;lt;- data.frame()
  for (i in 1:n_participants){
    a &amp;lt;- rnorm(n_trials, scores_baseline[i], variances[i])
    b &amp;lt;- rnorm(n_trials, scores_condition[i], variances[i])
    a &amp;lt;- a + rnorm(n_trials, 0, noise_sd[i]) # Add noise
    b &amp;lt;- b + rnorm(n_trials, 0, noise_sd[i]) # Add noise
    data &amp;lt;- rbind(data, data.frame(&amp;quot;Participant&amp;quot; = sprintf(&amp;quot;S%02d&amp;quot;, i),
                                   &amp;quot;Y&amp;quot; = c(a, b),
                                   &amp;quot;Score_True&amp;quot; = rep(c(scores_baseline[i], scores_condition[i]), each=n_trials),
                                   &amp;quot;Condition&amp;quot; = rep(c(&amp;quot;Baseline&amp;quot;, &amp;quot;Manipulation&amp;quot;), each=n_trials)))
  }
  data
}



# Visualize data -----------------------------------------------------------

p &amp;lt;- get_data(n_participants=20) %&amp;gt;%
  group_by(Participant, Condition) %&amp;gt;%
  mutate(mean = mean(Y)) %&amp;gt;%
  ggplot(aes(y=Y, x=Condition, fill=Participant, color=Participant, group=Participant)) +
  geom_line(aes(y=mean), position=position_dodge(width=0.66)) +
  ggdist::stat_eye(point_interval=ggdist::mean_hdi, alpha=0.66, position=position_dodge(width=0.66), .width = c(0.95)) +
  ylab(&amp;quot;Score&amp;quot;) +
  theme_modern() +
  theme(legend.position = &amp;quot;none&amp;quot;)
ggsave(&amp;quot;individual.png&amp;quot;, p, width=7, height=7, dpi=450)


# Get results -------------------------------------------------------------


get_results &amp;lt;- function(data){

  # Raw method ----

  results &amp;lt;- data %&amp;gt;%
    group_by(Participant, Condition) %&amp;gt;%
    summarise_all(mean) %&amp;gt;%
    rename(&amp;quot;Score_Raw&amp;quot; = &amp;quot;Y&amp;quot;) %&amp;gt;%
    arrange(Condition, Participant) %&amp;gt;%
    ungroup()


  # Population model ----

  model &amp;lt;- lme4::lmer(Y ~ Condition + (1 + Condition|Participant), data=data)

  fixed &amp;lt;- insight::get_parameters(model, effects =&amp;quot;fixed&amp;quot;)$Estimate
  random &amp;lt;- insight::get_parameters(model, effects =&amp;quot;random&amp;quot;)$Participant

  # Transform coefs into scores
  pop_baseline &amp;lt;- random[, 1] + fixed[1]
  pop_manipulation &amp;lt;- pop_baseline + random[, 2] + fixed[2]

  results$Score_PopulationModel &amp;lt;- c(pop_baseline, pop_manipulation)


  # Individual model ----

  individual_model_data &amp;lt;- data.frame()
  for(participant in unique(data$Participant)){
    cat(&amp;quot;.&amp;quot;)  # Print progress

    dat &amp;lt;- data[data$Participant==participant, ]

    # Frequentist
    model1 &amp;lt;-lm(Y ~ Condition, data=dat)
    nopriors &amp;lt;- parameters::parameters(model1)$Coefficient

    # Bayesian without priors
    model2 &amp;lt;-stan_glm(Y ~ Condition, data=dat, refresh=0)
    bayes &amp;lt;- parameters::parameters(model2)$Median

    # Bayesian with Priors
    model3 &amp;lt;-stan_glm(Y ~ Condition, data=dat, refresh=0,
                      prior = normal(fixed[1]),
                      prior_intercept = normal(fixed[2]))
    priors &amp;lt;- parameters::parameters(model3)$Median

    individual_model_data &amp;lt;- rbind(individual_model_data,
                                   data.frame(
      &amp;quot;Participant&amp;quot; = c(participant, participant),
      &amp;quot;Condition&amp;quot; = c(&amp;quot;Baseline&amp;quot;, &amp;quot;Manipulation&amp;quot;),
      &amp;quot;Score_IndividualModel_Freq&amp;quot; = c(nopriors[1], nopriors[1] + nopriors[2]),
      &amp;quot;Score_IndividualModel_Bayes&amp;quot; = c(bayes[1], bayes[1] + bayes[2]),
      &amp;quot;Score_IndividualModel_Priors&amp;quot; = c(priors[1], priors[1] + priors[2])
    ))
  }

  results &amp;lt;- merge(results, individual_model_data)


  # Clean output ----

  diff &amp;lt;- results %&amp;gt;%
    mutate(Diff_Raw = Score_True - Score_Raw,
           Diff_PopulationModel = Score_True - Score_PopulationModel,
           Diff_IndividualModel_Freq = Score_True - Score_IndividualModel_Freq,
           Diff_IndividualModel_Bayes = Score_True - Score_IndividualModel_Bayes,
           Diff_IndividualModel_Priors = Score_True - Score_IndividualModel_Priors) %&amp;gt;%
    select(Participant, Condition, starts_with(&amp;quot;Diff&amp;quot;)) %&amp;gt;%
    pivot_longer(starts_with(&amp;quot;Diff&amp;quot;), names_to=&amp;quot;Method&amp;quot;, values_to=&amp;quot;Diff&amp;quot;) %&amp;gt;%
    mutate(Diff_Abs = abs(Diff))

  diff
}



# Analysis ----------------------------------------------------------------

data &amp;lt;- get_data(n_participants=1000, n_trials=20, d=1, var=4, noise=0.3)
results &amp;lt;- get_results(data)

model &amp;lt;- lm(Diff_Abs ~ Method, data=results)

parameters::parameters(model)

means &amp;lt;- modelbased::estimate_means(model) %&amp;gt;%
  arrange(Mean) %&amp;gt;%
  mutate(Method = stringr::str_remove(Method, &amp;quot;Diff_&amp;quot;),
         Method = factor(Method, levels=Method))

contrasts &amp;lt;- modelbased::estimate_contrasts(model) %&amp;gt;%
  arrange(Difference) %&amp;gt;%
  mutate(Level1 = stringr::str_remove(Level1, &amp;quot;Diff_&amp;quot;),
         Level2 = stringr::str_remove(Level2, &amp;quot;Diff_&amp;quot;)) %&amp;gt;%
  select(Level1, Level2, Difference, CI_low, CI_high, p)

d &amp;lt;- list(&amp;quot;results&amp;quot;=results, &amp;quot;model&amp;quot;=model, &amp;quot;means&amp;quot;=means, &amp;quot;contrasts&amp;quot;=contrasts)
save(d, file=&amp;quot;data.Rdata&amp;quot;)



# Visualize means ---------------------------------------------------------

p &amp;lt;- means %&amp;gt;%
  ggplot(aes(x=Method, y=Mean, color=Method)) +
  geom_line(aes(group=1)) +
  geom_pointrange(aes(ymin=CI_low, ymax=CI_high), size=1) +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  scale_color_material(palette=&amp;quot;rainbow&amp;quot;)
ggsave(&amp;quot;featured.png&amp;quot;, p, width=10, height=6, dpi=450)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;sub&gt;You can reference this post as follows:&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;- Makowski, D. (2020, September 14). How to extract individual scores from repeated measures. Retrieved from &lt;a href=&#34;https://dominiquemakowski.github.io/post/individual_scores/&#34; class=&#34;uri&#34;&gt;https://dominiquemakowski.github.io/post/individual_scores/&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to share this post, and leave a comment below&lt;/em&gt; 🤗&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;And don’t forget to join me on Twitter&lt;/em&gt; &lt;span class=&#34;citation&#34;&gt;[@Dom_Makowski]&lt;/span&gt;(&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; class=&#34;uri&#34;&gt;https://twitter.com/Dom_Makowski&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to correctly analyze reaction time (RT) data</title>
      <link>https://dominiquemakowski.github.io/post/analyze_rt/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      <guid>https://dominiquemakowski.github.io/post/analyze_rt/</guid>
      <description>&lt;p&gt;This is a very, very important topic given the widespread usage of reaction times in psychology. Most of the time, we analyze it as a regular variable, using traditional models such as &lt;em&gt;linear models&lt;/em&gt;, &lt;em&gt;ANOVAs&lt;/em&gt; etc. The problem is that these models &lt;strong&gt;assume that the RT is normally distributed, which is false&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This leads us to adjustements like &lt;strong&gt;outliers removal&lt;/strong&gt; or &lt;strong&gt;log-transformation&lt;/strong&gt;, distorting the data because of our non-appropriate models.&lt;/p&gt;
&lt;p&gt;The good news is, it&amp;rsquo;s very easy to use better models, that account for the non-normal distribution of RT. And these alternatives are beautifully presented by 
&lt;a href=&#34;https://vbn.aau.dk/da/persons/117060&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas K. Lindeløv&lt;/a&gt; in the guide below:&lt;/p&gt;
&lt;p&gt;👉 
&lt;a href=&#34;https://lindeloev.github.io/shiny-rt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Reaction time distributions: an interactive overview&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;p&gt;It is a must-read for all psychologist. Do check-it out!!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; 🤗&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;And don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; 
&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>In defence of the 95% CI</title>
      <link>https://dominiquemakowski.github.io/post/defence_ci95/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>https://dominiquemakowski.github.io/post/defence_ci95/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; 
&lt;a href=&#34;https://github.com/easystats/bayestestR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;BayestestR&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;currently uses a 89% threshold by default for Credible Intervals (CI). Should we change that? If so, by what?&lt;/strong&gt; 
&lt;a href=&#34;https://github.com/easystats/bayestestR/issues/250&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;&lt;strong&gt;Join the discussion here.&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Magical numbers, or conventional thresholds, have bad press in statistics, and there are many of them. For instance, &lt;strong&gt;.05&lt;/strong&gt; (for the &lt;em&gt;p&lt;/em&gt;-value), or the &lt;strong&gt;95%&lt;/strong&gt; range for the &lt;strong&gt;Confidence Interval&lt;/strong&gt; (CI). Indeed, why 95 and not 94 or 90?&lt;/p&gt;
&lt;p&gt;👉 
&lt;a href=&#34;https://easystats.github.io/blog/posts/bayestestr_95/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Read my complete post on the easystats&amp;rsquo; blog&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; 🤗&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Bayesian statistics with R</title>
      <link>https://dominiquemakowski.github.io/post/intro_bayestestr/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      <guid>https://dominiquemakowski.github.io/post/intro_bayestestr/</guid>
      <description>&lt;p&gt;You are a student or a researcher interested in Bayesian statistics and R? But all the tutorials and courses that you have found are too intimidating?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fear no more!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With the 
&lt;a href=&#34;https://github.com/easystats/easystats&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;easystats team&lt;/a&gt;, we have created a very &lt;strong&gt;gentle&lt;/strong&gt; and &lt;strong&gt;introductory&lt;/strong&gt; course for beginners.&lt;/p&gt;
&lt;p&gt;You can find the link here:&lt;/p&gt;
&lt;p&gt;👉 
&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Get Started with Bayesian Statistics using R&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; 🤗&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; 
&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
