<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>p-value | Dr Dominique Makowski</title>
    <link>/tags/p-value/</link>
      <atom:link href="/tags/p-value/index.xml" rel="self" type="application/rss+xml" />
    <description>p-value</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 17 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hud75d04f2b1977d0bc7efdcf2aeb84fcd_760423_512x512_fill_lanczos_center_2.png</url>
      <title>p-value</title>
      <link>/tags/p-value/</link>
    </image>
    
    <item>
      <title>The Null Hypothesis Fallacy</title>
      <link>/post/null_hypothesis_fallacy/</link>
      <pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/null_hypothesis_fallacy/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The null hypothesis is a hallmark of experimental science, and the paradigm derived from it - the **null hypothesis significance testing (NHST) ** - has dominated the world of applied statistics in the last century. It has led to the invention and widespread usage of the infamous &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-value&lt;/strong&gt; and the related concept of &lt;strong&gt;significance&lt;/strong&gt;, but it can also be present in alternative frameworks such as Bayesian statistics. Interestingly, it became one of the combustible fuelling the recent controversies related to the &lt;strong&gt;reproducibility&lt;/strong&gt; and &lt;strong&gt;replicability&lt;/strong&gt; crises.&lt;/p&gt;
&lt;p&gt;In this series of posts, I will argue that the null hypothesis is not plausible, and examine the consequences of this fact, that will naturally lead me to elaborate an alternative framework for significance testing.&lt;/p&gt;
&lt;h2 id=&#34;absence-of-effect-vs-null-effect&#34;&gt;Absence of effect &lt;em&gt;vs.&lt;/em&gt; Null Effect&lt;/h2&gt;
&lt;p&gt;Most scientists are designing experiments to quantify or assess the existence of an &lt;strong&gt;effect&lt;/strong&gt; (a relationship between two things), to which a natural opposite seems to be the &lt;strong&gt;absence of effect&lt;/strong&gt;. These effects are usually operationalized as parameters - or coefficients - of some statistical models. Such models are akin to a simplified version of the world, which can be more or less complex, accurate, appropriate or sensitive to investigate a given effect.&lt;/p&gt;
&lt;p&gt;Interestingly, in most of statistical models, the &lt;em&gt;existence&lt;/em&gt; of effects (i.e., coefficients) is predetermined. We could, in theory, imagine a model in which we say &lt;em&gt;&amp;ldquo;here are 3 variables, V1, V2 and V3&amp;rdquo;&lt;/em&gt;, and the model would create parameters, for instance the correlation between &lt;em&gt;V1&lt;/em&gt; and &lt;em&gt;V3&lt;/em&gt;, only if said effect &lt;em&gt;is present&lt;/em&gt; (exists in the data). With such a model, it would be possible to tell whether an effect exists (i.e., if it&amp;rsquo;s present as a parameter), and if so investigate its properties (size, range, &amp;hellip;). The presence/absence of effects, a dichotomous concept by nature, would be directly transposable to the mathematics.&lt;/p&gt;
&lt;p&gt;But that&amp;rsquo;s not what happens. In general, the existence of a given parameter depends on the model specification, rather than on the data. This means that the researcher has to specify whether he wants to include the correlation between &lt;em&gt;V1&lt;/em&gt; and &lt;em&gt;V3&lt;/em&gt; in order to estimate it. This might seem trivial, but it has important consequences, as it leads to the &lt;em&gt;de facto&lt;/em&gt; swapping of &lt;strong&gt;absence of effects&lt;/strong&gt; for &lt;strong&gt;null effects&lt;/strong&gt;, which shifts the focus to the value of the effect, which is by nature a continuous concept.&lt;/p&gt;
&lt;p&gt;While most people would argue that &lt;strong&gt;no effect&lt;/strong&gt; and &lt;strong&gt;null effect&lt;/strong&gt; are equivalent, merely representing two ways of looking at the same phenomenon (&amp;ldquo;null effect&amp;rdquo; being the numerical, coefficient-focused, version of &amp;ldquo;no effect&amp;rdquo;), it is still important to note that null &lt;em&gt;vs.&lt;/em&gt; non-null effect is most of the time an artificial dichotomization of a continuous measure.&lt;/p&gt;
&lt;h2 id=&#34;a-null-effect-is-not-a-very-small-effect&#34;&gt;A Null Effect is not a Very Small Effect&lt;/h2&gt;
&lt;p&gt;The focus on the effect value is a double edged sword. Let&amp;rsquo;s take an effect (i.e., a coefficient) of &lt;code&gt;0.000001&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We all have a tendency to equate very small effects as &amp;ldquo;null&amp;rdquo; effects.&lt;/p&gt;
&lt;h2 id=&#34;null-effects-do-not-exist&#34;&gt;Null Effects Do Not Exist&lt;/h2&gt;
&lt;p&gt;Meehl‚Äôs (1967, 1978, 1990, 1997), in a series of demonstration (see also Waller, 2004), suggested that &lt;em&gt;&amp;ldquo;the null hypothesis, taken literally, is always false&amp;rdquo;&lt;/em&gt; (Meehl, 1978, p. 822). Based on strongly-powered personality datasets, he realised that the probability of two variables being significantly related is a function of sample size, and concluded that &lt;em&gt;&amp;ldquo;in social science everything correlates with almost everything else, theory aside&amp;rdquo;&lt;/em&gt; (Meehl, 1997, p. 393).&lt;/p&gt;
&lt;p&gt;I would like to extent this conclusion beyond social sciences or, as coined by Meehl or Waller (2004), &lt;em&gt;&amp;ldquo;soft psychology&amp;rdquo;&lt;/em&gt; (a term that I do not particularly like). Example of air pressure.&lt;/p&gt;
&lt;p&gt;This is a &lt;strong&gt;major issue&lt;/strong&gt;, as it means that any effect for which we cannot reject the null hypothesis (where &lt;em&gt;p&lt;/em&gt; &amp;gt; .05) can be interpreted as &lt;em&gt;&amp;quot;&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;no-effects-do-not-exist-either&#34;&gt;No Effects Do Not Exist Either&lt;/h2&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bayesian: quantify support in favour of the null&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Effect size &amp;amp; region of equivalence&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Third solution: change paradigm (SexIt).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Taken literally, the null hypothesis is always false. (as cited in Meehl, 1990, p 205). When this phenomenon is combined with the fact that very large samples can make every small effect a significant effect, one has to conclude that with the ideal sample (as large as possible) one have to reject every null hypothesis.&lt;/p&gt;
&lt;p&gt;This is problematic because this will turn research into a tautology. Every experiment that has a p-value &amp;gt; .05, will become a type II error since the sample was just not big enough to detect the effect. A solution could be to attach more importance to effect sizes and make them decisive in whether a null hypothesis should be rejected.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Waller, N. G. (2004). The fallacy of the null hypothesis in soft psychology. Applied and Preventive Psychology, 11(1), 83-86.&lt;/p&gt;
&lt;p&gt;Meehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of Science, 34, 103‚Äì115.&lt;/p&gt;
&lt;p&gt;Meehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology. Journal of Consulting and Clinical Psychology, 46, 806‚Äì834.&lt;/p&gt;
&lt;p&gt;Meehl, P. E. (1990). Appraising and amending theories: The strategy of Lakatosian defense and two principles that warrant using it. Psychological Inquiry, 1, 108‚Äì141, 173‚Äì180.&lt;/p&gt;
&lt;p&gt;Meehl, P. E. (1997). The problem is epistemology, not statistics: Replace significance tests by confidence intervals and quantify accuracy of risky numerical predictions. In L. L. Harlow, S. A. Mulaik, &amp;amp; J.H. Steiger (Eds.), What if there were no significance tests? (pp. 393‚Äì425). Mahwah, NJ: Erlbaum.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; ü§ó&lt;/p&gt;
&lt;p&gt;üê¶ &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; 
&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
